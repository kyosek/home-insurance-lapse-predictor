{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Analysis\n",
    "## Summary of this analysis\n",
    "### Logistic regression\n",
    "Here I use logistic regression as a benchmark model. This model is quite simple and computationally light but at the same time, it doesn't work well with imbalanced data. The F1-score for test set is 0.33, which looks so much space to be improved.\n",
    "\n",
    "### Random undersampling + Boosting\n",
    "This algorithm can balance the class imbalance at each iteration of the boosting algorithm, so that it can learn proper class balance. Also this algorithm uses decision tree as a base learner. Tree-based algorithms are generally good at learning the relations of complex features.\n",
    "\n",
    "The results show that it improved a lot comparison to logistic regression. This model flagged more customers that logistic regression model but precision decreased (the number of false positive increased).\n",
    "\n",
    "### XGBoost model\n",
    "Use XGBoost to improve the model performance. The advantages of this algorithm are:\n",
    "1. it is a tree-based model so that it can capture the complex relations of features\n",
    "2. Also a tree-based model are better at dealing with imbalanced data\n",
    "3. it is a boosting algorithm so that it is more robust to over-fitting \n",
    "4. it can produce the feature importance list\n",
    "5. it works also well with small dataset\n",
    "6. there are many parameters to tune\n",
    "\n",
    "The result shows that this model's F1 score is 0.5606 on the test set, which is so much improvement from the previous models. The confusion matrix is below.\n",
    "\n",
    "| Actual\\Prediction | Lapse       | Not lapse|\n",
    "| :---              |    :----:   |   :---:  |\n",
    "| Lapse             | 28907       | 11972    |\n",
    "| Not lapse         | 4936        | 10787    |\n",
    "\n",
    "From this confusion matrix, we can see that recall is higher - and lower precision. \n",
    "\n",
    "\n",
    "\n",
    "### 1D-CNN model\n",
    "This architecture is known with supreme predictive power. I was expecting with this model, it will improve the model performance but it was slightly worse than XGBoost model. Also due to time constrain, I didn't have time to fine-tune the model so it might be also the reason. \n",
    "\n",
    "\n",
    "### Prediction and Evaluation\n",
    "With XGBoost, the model performance improved to RMSE = 0.8167 with log value of preparation time in seconds. To be used in the business (easier interpretation), it needs to be transformed back to normal values. Also I think it is more usable to have the prediction in mins so I will transform it into mins. For further interpretability, I will evaluate the performance in mean absolute error (MAE).\n",
    "\n",
    "After transformed them into mins, the model showed that in average, there are 12.0 mins error, which seems quite big error for the business use case. However, considering 75% of orders are prepared within 1227 seconds (21 mins) and 95% of orders within 3021 seconds (50 mins), taking longer than those time would be assumed as outliers. Thus, I evaluate those orders which took less than 21 mins and 60 mins. The results are MAE = 4 mins and MAE = 5 mins, respectively.\n",
    "\n",
    "### Next steps\n",
    "As we have seen, quite a few outliers made this prediction more difficult. I guess those outliers are coming from several resons such as some accidents in the kitchen, some human errors (forgot to prepare the order), etc. So I would assume it would be difficult to predict. But we know these kind of things would happen with some probability (we are all human after all). If we could have much more data, we could build one more layer that would classify an order will take more than x mins, where x could be like 50 mins (if it\"s so important to have precise predictions for those outliers as a business). Also if we had more data, we could build a more complex model, namely neural network model so that it might be able to capture those outlier information better than XGBoost model.\n",
    "\n",
    "Potentially, this model can be consumed by the team working on logistics. If we could have precise predictions of preparation time, the logistics team can inform the users the precise estimate of delivery time and also can optimise the riders\" logistics. As riders do not have to wait at the restaurant to \"waste\" their time to deliver orders.\n",
    "\n",
    "## Table of contents\n",
    "[Prepare the input features](#Prepare-the-input-features)\n",
    "\n",
    "[Logistic regression](#Logistic-regression)\n",
    "\n",
    "[XGBoost](#XGBoost)\n",
    "- [Hyperparameter tuning](#Hyperparameter-tuning)\n",
    "- [Train](#Train)\n",
    "- [Prediction and Evaluation](#Prediction-and-Evaluation)\n",
    "\n",
    "[Next steps](#Next-steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import warnings\n",
    "import shap\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, auc\n",
    "import xgboost as xgb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/kyosuke/projects/home-insurance/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"resources/data/home_insurance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareInputs(df: \"pd.dataFrame\") -> \"pd.dataFrame\":\n",
    "    \"\"\"Prepare the input for training\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): raw data\n",
    "        \n",
    "    Process:\n",
    "        1. Exclude missing values\n",
    "        2. Clean the target variable\n",
    "        3. Create dummy variables for categorical variables\n",
    "        4. Create age features\n",
    "        5. Impute missing value\n",
    "    \n",
    "    Return: pd.dataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Exclude missing values\n",
    "    df = df[df[\"POL_STATUS\"].notnull()]\n",
    "    \n",
    "    # 2. Clean the target variable\n",
    "    df = df[df[\"POL_STATUS\"] != \"Unknown\"]\n",
    "    df[\"lapse\"] = np.where(df[\"POL_STATUS\"] == \"Lapsed\", 1, 0)\n",
    "    \n",
    "    # 3. Create dummy variables for categorical variables\n",
    "    categorical_cols = [\"CLAIM3YEARS\", \"BUS_USE\", \"AD_BUILDINGS\",\n",
    "                        \"APPR_ALARM\", \"CONTENTS_COVER\", \"P1_SEX\",\n",
    "                        \"BUILDINGS_COVER\", \"P1_POLICY_REFUSED\", \n",
    "                        \"APPR_LOCKS\", \"FLOODING\",\n",
    "                        \"NEIGH_WATCH\", \"SAFE_INSTALLED\", \"SEC_DISC_REQ\",\n",
    "                        \"SUBSIDENCE\", \"LEGAL_ADDON_POST_REN\", \n",
    "                        \"HOME_EM_ADDON_PRE_REN\",\"HOME_EM_ADDON_POST_REN\", \n",
    "                        \"GARDEN_ADDON_PRE_REN\", \"GARDEN_ADDON_POST_REN\", \n",
    "                        \"KEYCARE_ADDON_PRE_REN\", \"KEYCARE_ADDON_POST_REN\", \n",
    "                        \"HP1_ADDON_PRE_REN\", \"HP1_ADDON_POST_REN\",\n",
    "                        \"HP2_ADDON_PRE_REN\", \"HP2_ADDON_POST_REN\", \n",
    "                        \"HP3_ADDON_PRE_REN\", \"HP3_ADDON_POST_REN\", \n",
    "                        \"MTA_FLAG\", \"OCC_STATUS\", \"OWNERSHIP_TYPE\",\n",
    "                        \"PROP_TYPE\", \"PAYMENT_METHOD\", \"P1_EMP_STATUS\",\n",
    "                        \"P1_MAR_STATUS\"\n",
    "                        ]\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        dummies = pd.get_dummies(df[col], \n",
    "                                 drop_first = True,\n",
    "                                 prefix = col\n",
    "                                )\n",
    "        df = pd.concat([df, dummies], 1)\n",
    "    \n",
    "    # 4. Create age features\n",
    "    df[\"age\"] = (datetime.strptime(\"2013-01-01\", \"%Y-%m-%d\") - pd.to_datetime(df[\"P1_DOB\"])).dt.days // 365\n",
    "    df[\"property_age\"] = 2013 - df[\"YEARBUILT\"]\n",
    "    df[\"cover_length\"] = 2013 - pd.to_datetime(df[\"COVER_START\"]).dt.year\n",
    "    \n",
    "    # 5. Impute missing value\n",
    "    df[\"RISK_RATED_AREA_B_imputed\"] = df[\"RISK_RATED_AREA_B\"].fillna(df[\"RISK_RATED_AREA_B\"].mean())\n",
    "    df[\"RISK_RATED_AREA_C_imputed\"] = df[\"RISK_RATED_AREA_C\"].fillna(df[\"RISK_RATED_AREA_C\"].mean())\n",
    "    df[\"MTA_FAP_imputed\"] = df[\"MTA_FAP\"].fillna(0)\n",
    "    df[\"MTA_APRP_imputed\"] = df[\"MTA_APRP\"].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATS = [\n",
    "#          \"CLAIM3YEARS_Y\", \"BUS_USE_Y\", \"AD_BUILDINGS_Y\",\n",
    "#          \"CONTENTS_COVER_Y\", \"P1_SEX_M\", \"P1_SEX_N\", \"BUILDINGS_COVER_Y\", \n",
    "#          \"P1_POLICY_REFUSED_Y\", \"APPR_ALARM_Y\", \"APPR_LOCKS_Y\", \"FLOODING_Y\", \n",
    "#          \"NEIGH_WATCH_Y\", \"SAFE_INSTALLED_Y\", \"SEC_DISC_REQ_Y\", \"SUBSIDENCE_Y\", \n",
    "#          \"LEGAL_ADDON_POST_REN_Y\", \"HOME_EM_ADDON_PRE_REN_Y\", \n",
    "#          \"HOME_EM_ADDON_POST_REN_Y\", \"GARDEN_ADDON_PRE_REN_Y\",\n",
    "#          \"GARDEN_ADDON_POST_REN_Y\", \"KEYCARE_ADDON_PRE_REN_Y\", \n",
    "#          \"KEYCARE_ADDON_POST_REN_Y\", \"HP1_ADDON_PRE_REN_Y\", \"HP1_ADDON_POST_REN_Y\", \n",
    "#          \"HP2_ADDON_PRE_REN_Y\", \"HP2_ADDON_POST_REN_Y\", \"HP3_ADDON_PRE_REN_Y\", \n",
    "#          \"HP3_ADDON_POST_REN_Y\", \"MTA_FLAG_Y\", \"OCC_STATUS_LP\",\n",
    "#          \"OCC_STATUS_PH\", \"OCC_STATUS_UN\", \"OCC_STATUS_WD\",\n",
    "#          \"OWNERSHIP_TYPE_2.0\", \"OWNERSHIP_TYPE_3.0\", \"OWNERSHIP_TYPE_6.0\", \n",
    "#          \"OWNERSHIP_TYPE_7.0\", \"OWNERSHIP_TYPE_8.0\", \"OWNERSHIP_TYPE_11.0\", \n",
    "#          \"OWNERSHIP_TYPE_12.0\", \"OWNERSHIP_TYPE_13.0\", \"OWNERSHIP_TYPE_14.0\", \n",
    "#          \"OWNERSHIP_TYPE_16.0\", \"OWNERSHIP_TYPE_17.0\", \n",
    "#          \"OWNERSHIP_TYPE_18.0\", \"PROP_TYPE_2.0\", \"PROP_TYPE_3.0\", \"PROP_TYPE_4.0\", \n",
    "#          \"PROP_TYPE_7.0\", \"PROP_TYPE_9.0\", \"PROP_TYPE_10.0\", \n",
    "#          \"PROP_TYPE_16.0\", \"PROP_TYPE_17.0\", \"PROP_TYPE_18.0\", \"PROP_TYPE_19.0\", \n",
    "#          \"PROP_TYPE_20.0\", \"PROP_TYPE_21.0\", \"PROP_TYPE_22.0\", \"PROP_TYPE_23.0\", \n",
    "#          \"PROP_TYPE_24.0\", \"PROP_TYPE_25.0\", \"PROP_TYPE_26.0\", \"PROP_TYPE_27.0\", \n",
    "#          \"PROP_TYPE_29.0\", \"PROP_TYPE_30.0\", \"PROP_TYPE_31.0\", \n",
    "#          \"PROP_TYPE_32.0\", \"PROP_TYPE_37.0\", \"PROP_TYPE_39.0\", \n",
    "#          \"PROP_TYPE_40.0\", \"PROP_TYPE_44.0\", \"PROP_TYPE_45.0\", \"PROP_TYPE_47.0\", \n",
    "#          \"PROP_TYPE_48.0\", \"PROP_TYPE_51.0\", \"PROP_TYPE_52.0\", \"PROP_TYPE_53.0\", \n",
    "#          \"PAYMENT_METHOD_NonDD\", \"PAYMENT_METHOD_PureDD\", \"P1_EMP_STATUS_C\", \n",
    "#          \"P1_EMP_STATUS_E\", \"P1_EMP_STATUS_F\", \"P1_EMP_STATUS_H\", \"P1_EMP_STATUS_I\", \n",
    "#          \"P1_EMP_STATUS_N\", \"P1_EMP_STATUS_R\", \"P1_EMP_STATUS_S\", \"P1_EMP_STATUS_U\", \n",
    "#          \"P1_EMP_STATUS_V\", \"P1_MAR_STATUS_B\", \"P1_MAR_STATUS_C\", \"P1_MAR_STATUS_D\", \n",
    "#          \"P1_MAR_STATUS_M\", \"P1_MAR_STATUS_N\", \"P1_MAR_STATUS_O\", \"P1_MAR_STATUS_P\", \n",
    "#          \"P1_MAR_STATUS_S\", \"P1_MAR_STATUS_W\", \n",
    "#          \"age\", \"property_age\", \"cover_length\", \"RISK_RATED_AREA_B_imputed\", \n",
    "#          \"RISK_RATED_AREA_C_imputed\", \"MTA_FAP_imputed\", \"MTA_APRP_imputed\",\n",
    "#          \"SUM_INSURED_BUILDINGS\", \"NCD_GRANTED_YEARS_B\", \"SUM_INSURED_CONTENTS\", \n",
    "#          \"NCD_GRANTED_YEARS_C\", \"SPEC_SUM_INSURED\", \"SPEC_ITEM_PREM\", \n",
    "#          \"UNSPEC_HRP_PREM\", \"BEDROOMS\", \"MAX_DAYS_UNOCC\", \"LAST_ANN_PREM_GROSS\"\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = [\n",
    "        'P1_MAR_STATUS_P', 'PAYMENT_METHOD_NonDD', 'AD_BUILDINGS_Y',\n",
    "        'HOME_EM_ADDON_POST_REN_Y', 'KEYCARE_ADDON_PRE_REN_Y', 'MAX_DAYS_UNOCC',\n",
    "        'HP1_ADDON_POST_REN_Y', 'HP2_ADDON_POST_REN_Y',\n",
    "        'LEGAL_ADDON_POST_REN_Y', 'PAYMENT_METHOD_PureDD',\n",
    "        'HP3_ADDON_POST_REN_Y', 'GARDEN_ADDON_PRE_REN_Y',\n",
    "        'GARDEN_ADDON_POST_REN_Y', 'KEYCARE_ADDON_POST_REN_Y',\n",
    "        'SUM_INSURED_BUILDINGS', 'HOME_EM_ADDON_PRE_REN_Y', 'OCC_STATUS_LP',\n",
    "        'P1_MAR_STATUS_O', 'OCC_STATUS_PH', 'PROP_TYPE_51.0', 'PROP_TYPE_2.0',\n",
    "        'NCD_GRANTED_YEARS_B', 'MTA_FLAG_Y', 'cover_length', 'PROP_TYPE_22.0',\n",
    "        'BUILDINGS_COVER_Y', 'SUBSIDENCE_Y', 'NCD_GRANTED_YEARS_C',\n",
    "        'RISK_RATED_AREA_C_imputed', 'RISK_RATED_AREA_B_imputed',\n",
    "        'SAFE_INSTALLED_Y', 'FLOODING_Y', 'P1_MAR_STATUS_C', 'PROP_TYPE_18.0',\n",
    "        'UNSPEC_HRP_PREM', 'SUM_INSURED_CONTENTS', 'PROP_TYPE_32.0',\n",
    "        'LAST_ANN_PREM_GROSS', 'PROP_TYPE_53.0', 'SPEC_ITEM_PREM',\n",
    "        'MTA_FAP_imputed', 'P1_MAR_STATUS_D', 'HP2_ADDON_PRE_REN_Y',\n",
    "        'P1_MAR_STATUS_M', 'MTA_APRP_imputed', 'PROP_TYPE_16.0',\n",
    "        'PROP_TYPE_17.0', 'PROP_TYPE_48.0', 'SPEC_SUM_INSURED',\n",
    "        'PROP_TYPE_47.0', 'PROP_TYPE_4.0', 'P1_EMP_STATUS_H', 'P1_EMP_STATUS_U',\n",
    "        'P1_EMP_STATUS_S', 'CLAIM3YEARS_Y', 'OWNERSHIP_TYPE_7.0',\n",
    "        'PROP_TYPE_45.0', 'BUS_USE_Y', 'P1_EMP_STATUS_N', 'property_age',\n",
    "        'P1_MAR_STATUS_S', 'PROP_TYPE_7.0', 'PROP_TYPE_9.0', 'PROP_TYPE_19.0',\n",
    "        'PROP_TYPE_25.0', 'P1_MAR_STATUS_W', 'age', 'APPR_ALARM_Y', 'BEDROOMS',\n",
    "        'PROP_TYPE_26.0', 'OCC_STATUS_UN', 'P1_EMP_STATUS_R', 'SEC_DISC_REQ_Y',\n",
    "        'OWNERSHIP_TYPE_18.0', 'P1_EMP_STATUS_E', 'OWNERSHIP_TYPE_3.0',\n",
    "        'OWNERSHIP_TYPE_12.0', 'APPR_LOCKS_Y', 'OWNERSHIP_TYPE_14.0',\n",
    "        'OWNERSHIP_TYPE_8.0', 'OWNERSHIP_TYPE_13.0', 'PROP_TYPE_10.0',\n",
    "        'NEIGH_WATCH_Y', 'PROP_TYPE_31.0', 'PROP_TYPE_52.0', 'P1_SEX_M',\n",
    "        'OWNERSHIP_TYPE_2.0'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "train, test = train_test_split(df, test_size = .3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = prepareInputs(train), prepareInputs(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train[FEATS], train[\"lapse\"], test[FEATS], test[\"lapse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the data sets\n",
    "numerical_cols = [\n",
    "    \"age\", \"property_age\", \"cover_length\", \"RISK_RATED_AREA_B_imputed\", \n",
    "    \"RISK_RATED_AREA_C_imputed\", \"MTA_FAP_imputed\", \"MTA_APRP_imputed\",\n",
    "    \"SUM_INSURED_BUILDINGS\", \"NCD_GRANTED_YEARS_B\", \"SUM_INSURED_CONTENTS\", \n",
    "    \"NCD_GRANTED_YEARS_C\", \"SPEC_SUM_INSURED\", \"SPEC_ITEM_PREM\", \n",
    "    \"UNSPEC_HRP_PREM\", \"BEDROOMS\", \"MAX_DAYS_UNOCC\", \"LAST_ANN_PREM_GROSS\"\n",
    "]\n",
    "\n",
    "for col in numerical_cols:\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train[col] = scaler.fit_transform(X_train[[col]])\n",
    "    X_test[col] = scaler.transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio of lapse class in training set is 27.8%\n",
      "The ratio of lapse class in test set is 27.78%\n"
     ]
    }
   ],
   "source": [
    "print(\"The ratio of lapse class in training set is \" +\n",
    "      str(round(y_train.sum()/len(y_train) * 100, 2)) +\n",
    "      \"%\"\n",
    "     )\n",
    "\n",
    "print(\"The ratio of lapse class in test set is \" +\n",
    "      str(round(y_test.sum()/len(y_test)* 100, 2)) +\n",
    "      \"%\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "Here I use logistic regression as a benchmark model. This model is quite simple and computationally light but at the same time, it doesn't work well with imbalanced data. The F1-score for test set is 0.33, which looks so much space to be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(random_state = 42).fit(X_train, y_train)\n",
    "\n",
    "prediction_train = logit.predict(X_train)\n",
    "prediction = logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set is 0.7415\n",
      "Accuracy for test set is 0.7435\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for training set is \" + str(round(accuracy_score(y_train, prediction_train),4)))\n",
    "print(\"Accuracy for test set is \" + str(round(accuracy_score(y_test, prediction),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set is 0.3208\n",
      "F1 score for test set is 0.3301\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score for training set is \" + str(round(f1_score(y_train, prediction_train),4)))\n",
    "print(\"F1 score for test set is \" + str(round(f1_score(y_test, prediction),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38506,  2373],\n",
       "       [12146,  3577]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random undersampling + Boosting\n",
    "This algorithm can balance the class imbalance at each iteration of the boosting algorithm, so that it can learn proper class balance. Also this algorithm uses decision tree as a base learner. Tree-based algorithms are generally good at learning the relations of complex features.\n",
    "\n",
    "The results show that it improved a lot comparison to logistic regression. This model flagged more customers that logistic regression model but precision decreased (the number of false positive increased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusboost = RUSBoostClassifier(random_state = 42)\n",
    "\n",
    "rusboost.fit(X_train, y_train)\n",
    "\n",
    "prediction_train_rusb = rusboost.predict(X_train)\n",
    "prediction_rusb = rusboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set is 0.6654\n",
      "Accuracy for test set is 0.6649\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for training set is \" + str(round(accuracy_score(y_train, prediction_train_rusb),4)))\n",
    "print(\"Accuracy for test set is \" + str(round(accuracy_score(y_test, prediction_rusb),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set is 0.5265\n",
      "F1 score for test set is 0.5276\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score for training set is \" + str(round(f1_score(y_train, prediction_train_rusb),4)))\n",
    "print(\"F1 score for test set is \" + str(round(f1_score(y_test, prediction_rusb),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27040, 13839],\n",
       "       [ 5131, 10592]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction_rusb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model\n",
    "Use XGBoost to improve the model performance. The advantages of this algorithm are:\n",
    "1. it is a tree-based model so that it can capture the complex relations of features\n",
    "2. Also a tree-based model are better at dealing with imbalanced data\n",
    "3. it is a boosting algorithm so that it is more robust to over-fitting \n",
    "4. it can produce the feature importance list\n",
    "5. it works also well with small dataset\n",
    "6. there are many parameters to tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = [\n",
    "    (eta,max_depth,min_child_weight,\n",
    "    subsample,objective,eval_metric,\n",
    "    grow_policy)\n",
    "    for eta in [i/100. for i in range(1,3,1)]\n",
    "    for max_depth in range(6, 12, 2)\n",
    "    for min_child_weight in range(5,8,1)\n",
    "    for subsample in [i/10. for i in range(5,7,1)]\n",
    "    for objective in ['binary:logistic']\n",
    "    for eval_metric in ['auc', 'logloss', 'error']\n",
    "    for grow_policy in ['depthwise','lossguide']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters to be updated\n",
    "params = {\n",
    "            'eta': .03,\n",
    "            'max_depth': 8,\n",
    "            'min_child_weight': 0,\n",
    "            'subsample': 1,\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'grow_policy': 'depthwise'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters is 216\n"
     ]
    }
   ],
   "source": [
    "print(\"number of parameters is \" + str(len(search_params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2600924 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2600924 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2600924 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2600924 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2600924 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2600924 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.260689 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.260689 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.260689 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.260689 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.260689 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.260689 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2600242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2600242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2600242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2600242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2600242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2600242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.260719 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.260719 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.260719 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.260719 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.260719 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.260719 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.260198 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.260198 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.260198 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.260198 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.260198 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.260198 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.26084759999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.26084759999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.26084759999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.26084759999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.26084759999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.26084759999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2521242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2521242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2521242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2521242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2521242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2521242 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.25249399999999994 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.25249399999999994 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.25249399999999994 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.25249399999999994 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.25249399999999994 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.25249399999999994 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.25208620000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.25208620000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.25208620000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.25208620000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.25208620000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.25208620000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2524184 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2524184 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2524184 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2524184 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2524184 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2524184 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.25220719999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.25220719999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.25220719999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.25220719999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.25220719999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.25220719999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.25261520000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.25261520000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.25261520000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.25261520000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.25261520000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.25261520000000004 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2472678 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2472678 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2472678 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2472678 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2472678 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2472678 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2478342 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2478342 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2478342 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2478342 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2478342 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2478342 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.24756240000000002 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.24756240000000002 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.24756240000000002 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.24756240000000002 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.24756240000000002 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.24756240000000002 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2475774 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2475774 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2475774 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2475774 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2475774 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2475774 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.24768299999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.24768299999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.24768299999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.24768299999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.24768299999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.24768299999999996 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.24778879999999998 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.24778879999999998 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.24778879999999998 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.24778879999999998 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.24778879999999998 for 500 rounds\n",
      "CV with eta=0.01, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.24778879999999998 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2600998 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2600998 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2600998 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2600998 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2600998 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2600998 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2605004 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2605004 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2605004 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2605004 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2605004 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2605004 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2601452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2601452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2601452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2601452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2601452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2601452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2603942 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2602128 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2602128 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2602128 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2602128 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2602128 for 500 rounds\n",
      "CV with eta=0.02, max_depth=6, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2602128 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2517316 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2517316 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2517316 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2517316 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2517316 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2517316 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.252109 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.252109 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.252109 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.252109 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.252109 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.252109 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.25176160000000003 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.25176160000000003 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.25176160000000003 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.25176160000000003 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.25176160000000003 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.25176160000000003 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2519882 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2519882 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2519882 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2519882 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2519882 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2519882 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.251739 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.251739 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.251739 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.251739 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.251739 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.251739 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2522146 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2522146 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2522146 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2522146 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2522146 for 500 rounds\n",
      "CV with eta=0.02, max_depth=8, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2522146 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.24698059999999997 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.24698059999999997 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.24698059999999997 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.24698059999999997 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.24698059999999997 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.24698059999999997 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2476156 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2476156 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2476156 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2476156 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2476156 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=5, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2476156 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.2472452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.2472452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.2472452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.2472452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.2472452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.2472452 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.247517 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.247517 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.247517 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.247517 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.247517 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=6, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.247517 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.24704120000000002 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.24704120000000002 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.24704120000000002 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.24704120000000002 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.24704120000000002 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.5, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.24704120000000002 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise\n",
      "\tError 0.24757780000000001 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=auc, grow_policy=lossguide\n",
      "\tError 0.24757780000000001 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=depthwise\n",
      "\tError 0.24757780000000001 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=logloss, grow_policy=lossguide\n",
      "\tError 0.24757780000000001 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=depthwise\n",
      "\tError 0.24757780000000001 for 500 rounds\n",
      "CV with eta=0.02, max_depth=10, min_child_weight=7, subsample=0.6, objective=binary:logistic, eval_metric=error, grow_policy=lossguide\n",
      "\tError 0.24757780000000001 for 500 rounds\n",
      "Best params: eat=0.02, max_depth=10, min_child_weight=5,        subsample=0.5, objective=binary:logistic, eval_metric=auc, grow_policy=depthwise,        Error: 0.24698059999999997\n"
     ]
    }
   ],
   "source": [
    "boost_rounds = 500\n",
    "min_error = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta, max_depth, min_child_weight,subsample,objective,eval_metric,grow_policy in search_params:\n",
    "    print(\"CV with eta={}, max_depth={}, min_child_weight={}, subsample={}, objective={}, eval_metric={}, grow_policy={}\".format(\n",
    "        eta,\n",
    "        max_depth,\n",
    "        min_child_weight,\n",
    "        subsample,\n",
    "        objective,\n",
    "        eval_metric,\n",
    "        grow_policy\n",
    "    ))\n",
    "    \n",
    "    # Update parameters\n",
    "    params['eta'] = eta\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    params['subsample'] = subsample\n",
    "    params['objective'] = objective\n",
    "    params['eval_metric'] = eval_metric\n",
    "    params['grow_policy'] = grow_policy\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        xgb.DMatrix(X_train, y_train),\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics=['error'],\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    # Update best error score\n",
    "    mean_error = cv_results['test-error-mean'].min()\n",
    "    print(\"\\tError {} for {} rounds\".format(mean_error, boost_rounds))\n",
    "    if mean_error < min_error:\n",
    "        min_error = mean_error\n",
    "        best_params = (eta,max_depth,min_child_weight,subsample,objective,eval_metric,grow_policy)\n",
    "        \n",
    "        params = {\n",
    "            'eta': best_params[0],\n",
    "            'max_depth': best_params[1],\n",
    "            'min_child_weight': best_params[2],\n",
    "            'subsample': best_params[3],\n",
    "            'objective': best_params[4],\n",
    "            'eval_metric': best_params[5],\n",
    "            'grow_policy': best_params[6]\n",
    "        }\n",
    "        \n",
    "print(\"Best params: eat={}, max_depth={}, min_child_weight={},\\\n",
    "        subsample={}, objective={}, eval_metric={}, grow_policy={},\\\n",
    "        Error: {}\".format(best_params[0], best_params[1],best_params[2], best_params[3],best_params[4],best_params[5], best_params[6], min_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.02,\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 7,\n",
       " 'subsample': 0.6,\n",
       " 'objective': 'binary:logistic',\n",
       " 'eval_metric': 'error',\n",
       " 'grow_policy': 'lossguide'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.24889\ttest-error:0.25142\n",
      "[1]\ttrain-error:0.24546\ttest-error:0.24773\n",
      "[2]\ttrain-error:0.24406\ttest-error:0.24679\n",
      "[3]\ttrain-error:0.24407\ttest-error:0.24580\n",
      "[4]\ttrain-error:0.24280\ttest-error:0.24538\n",
      "[5]\ttrain-error:0.24268\ttest-error:0.24591\n",
      "[6]\ttrain-error:0.24265\ttest-error:0.24526\n",
      "[7]\ttrain-error:0.24255\ttest-error:0.24550\n",
      "[8]\ttrain-error:0.24236\ttest-error:0.24549\n",
      "[9]\ttrain-error:0.24181\ttest-error:0.24462\n",
      "[10]\ttrain-error:0.24188\ttest-error:0.24482\n",
      "[11]\ttrain-error:0.24172\ttest-error:0.24554\n",
      "[12]\ttrain-error:0.24172\ttest-error:0.24503\n",
      "[13]\ttrain-error:0.24145\ttest-error:0.24455\n",
      "[14]\ttrain-error:0.24157\ttest-error:0.24455\n",
      "[15]\ttrain-error:0.24150\ttest-error:0.24466\n",
      "[16]\ttrain-error:0.24161\ttest-error:0.24476\n",
      "[17]\ttrain-error:0.24144\ttest-error:0.24488\n",
      "[18]\ttrain-error:0.24145\ttest-error:0.24469\n",
      "[19]\ttrain-error:0.24135\ttest-error:0.24476\n",
      "[20]\ttrain-error:0.24157\ttest-error:0.24458\n",
      "[21]\ttrain-error:0.24122\ttest-error:0.24467\n",
      "[22]\ttrain-error:0.24119\ttest-error:0.24462\n",
      "[23]\ttrain-error:0.24118\ttest-error:0.24448\n",
      "[24]\ttrain-error:0.24068\ttest-error:0.24446\n",
      "[25]\ttrain-error:0.24060\ttest-error:0.24423\n",
      "[26]\ttrain-error:0.24061\ttest-error:0.24423\n",
      "[27]\ttrain-error:0.24052\ttest-error:0.24409\n",
      "[28]\ttrain-error:0.24030\ttest-error:0.24391\n",
      "[29]\ttrain-error:0.24035\ttest-error:0.24388\n",
      "[30]\ttrain-error:0.24002\ttest-error:0.24405\n",
      "[31]\ttrain-error:0.23972\ttest-error:0.24351\n",
      "[32]\ttrain-error:0.23946\ttest-error:0.24328\n",
      "[33]\ttrain-error:0.23922\ttest-error:0.24299\n",
      "[34]\ttrain-error:0.23887\ttest-error:0.24312\n",
      "[35]\ttrain-error:0.23859\ttest-error:0.24282\n",
      "[36]\ttrain-error:0.23824\ttest-error:0.24282\n",
      "[37]\ttrain-error:0.23847\ttest-error:0.24269\n",
      "[38]\ttrain-error:0.23833\ttest-error:0.24262\n",
      "[39]\ttrain-error:0.23818\ttest-error:0.24229\n",
      "[40]\ttrain-error:0.23786\ttest-error:0.24259\n",
      "[41]\ttrain-error:0.23787\ttest-error:0.24243\n",
      "[42]\ttrain-error:0.23763\ttest-error:0.24218\n",
      "[43]\ttrain-error:0.23761\ttest-error:0.24213\n",
      "[44]\ttrain-error:0.23748\ttest-error:0.24204\n",
      "[45]\ttrain-error:0.23737\ttest-error:0.24192\n",
      "[46]\ttrain-error:0.23709\ttest-error:0.24201\n",
      "[47]\ttrain-error:0.23703\ttest-error:0.24213\n",
      "[48]\ttrain-error:0.23681\ttest-error:0.24199\n",
      "[49]\ttrain-error:0.23682\ttest-error:0.24199\n",
      "[50]\ttrain-error:0.23658\ttest-error:0.24172\n",
      "[51]\ttrain-error:0.23648\ttest-error:0.24155\n",
      "[52]\ttrain-error:0.23628\ttest-error:0.24133\n",
      "[53]\ttrain-error:0.23608\ttest-error:0.24128\n",
      "[54]\ttrain-error:0.23597\ttest-error:0.24114\n",
      "[55]\ttrain-error:0.23597\ttest-error:0.24105\n",
      "[56]\ttrain-error:0.23570\ttest-error:0.24107\n",
      "[57]\ttrain-error:0.23583\ttest-error:0.24080\n",
      "[58]\ttrain-error:0.23577\ttest-error:0.24089\n",
      "[59]\ttrain-error:0.23555\ttest-error:0.24072\n",
      "[60]\ttrain-error:0.23542\ttest-error:0.24066\n",
      "[61]\ttrain-error:0.23531\ttest-error:0.24070\n",
      "[62]\ttrain-error:0.23518\ttest-error:0.24079\n",
      "[63]\ttrain-error:0.23496\ttest-error:0.24066\n",
      "[64]\ttrain-error:0.23503\ttest-error:0.24064\n",
      "[65]\ttrain-error:0.23503\ttest-error:0.24068\n",
      "[66]\ttrain-error:0.23493\ttest-error:0.24056\n",
      "[67]\ttrain-error:0.23484\ttest-error:0.24049\n",
      "[68]\ttrain-error:0.23484\ttest-error:0.24029\n",
      "[69]\ttrain-error:0.23487\ttest-error:0.24001\n",
      "[70]\ttrain-error:0.23472\ttest-error:0.24019\n",
      "[71]\ttrain-error:0.23456\ttest-error:0.24008\n",
      "[72]\ttrain-error:0.23432\ttest-error:0.23974\n",
      "[73]\ttrain-error:0.23418\ttest-error:0.23985\n",
      "[74]\ttrain-error:0.23413\ttest-error:0.23973\n",
      "[75]\ttrain-error:0.23398\ttest-error:0.23958\n",
      "[76]\ttrain-error:0.23381\ttest-error:0.23953\n",
      "[77]\ttrain-error:0.23364\ttest-error:0.23953\n",
      "[78]\ttrain-error:0.23333\ttest-error:0.23955\n",
      "[79]\ttrain-error:0.23320\ttest-error:0.23953\n",
      "[80]\ttrain-error:0.23289\ttest-error:0.23927\n",
      "[81]\ttrain-error:0.23267\ttest-error:0.23920\n",
      "[82]\ttrain-error:0.23247\ttest-error:0.23904\n",
      "[83]\ttrain-error:0.23214\ttest-error:0.23877\n",
      "[84]\ttrain-error:0.23204\ttest-error:0.23888\n",
      "[85]\ttrain-error:0.23193\ttest-error:0.23867\n",
      "[86]\ttrain-error:0.23203\ttest-error:0.23861\n",
      "[87]\ttrain-error:0.23175\ttest-error:0.23865\n",
      "[88]\ttrain-error:0.23175\ttest-error:0.23865\n",
      "[89]\ttrain-error:0.23160\ttest-error:0.23852\n",
      "[90]\ttrain-error:0.23151\ttest-error:0.23833\n",
      "[91]\ttrain-error:0.23128\ttest-error:0.23833\n",
      "[92]\ttrain-error:0.23130\ttest-error:0.23845\n",
      "[93]\ttrain-error:0.23101\ttest-error:0.23830\n",
      "[94]\ttrain-error:0.23080\ttest-error:0.23821\n",
      "[95]\ttrain-error:0.23071\ttest-error:0.23794\n",
      "[96]\ttrain-error:0.23067\ttest-error:0.23798\n",
      "[97]\ttrain-error:0.23062\ttest-error:0.23782\n",
      "[98]\ttrain-error:0.23064\ttest-error:0.23780\n",
      "[99]\ttrain-error:0.23057\ttest-error:0.23769\n",
      "[100]\ttrain-error:0.23037\ttest-error:0.23757\n",
      "[101]\ttrain-error:0.23032\ttest-error:0.23757\n",
      "[102]\ttrain-error:0.23021\ttest-error:0.23748\n",
      "[103]\ttrain-error:0.23009\ttest-error:0.23768\n",
      "[104]\ttrain-error:0.23009\ttest-error:0.23769\n",
      "[105]\ttrain-error:0.23000\ttest-error:0.23759\n",
      "[106]\ttrain-error:0.23004\ttest-error:0.23743\n",
      "[107]\ttrain-error:0.22997\ttest-error:0.23750\n",
      "[108]\ttrain-error:0.22966\ttest-error:0.23718\n",
      "[109]\ttrain-error:0.22970\ttest-error:0.23731\n",
      "[110]\ttrain-error:0.22940\ttest-error:0.23709\n",
      "[111]\ttrain-error:0.22929\ttest-error:0.23692\n",
      "[112]\ttrain-error:0.22921\ttest-error:0.23697\n",
      "[113]\ttrain-error:0.22925\ttest-error:0.23694\n",
      "[114]\ttrain-error:0.22911\ttest-error:0.23672\n",
      "[115]\ttrain-error:0.22912\ttest-error:0.23669\n",
      "[116]\ttrain-error:0.22895\ttest-error:0.23662\n",
      "[117]\ttrain-error:0.22878\ttest-error:0.23641\n",
      "[118]\ttrain-error:0.22858\ttest-error:0.23614\n",
      "[119]\ttrain-error:0.22851\ttest-error:0.23616\n",
      "[120]\ttrain-error:0.22843\ttest-error:0.23607\n",
      "[121]\ttrain-error:0.22839\ttest-error:0.23596\n",
      "[122]\ttrain-error:0.22813\ttest-error:0.23580\n",
      "[123]\ttrain-error:0.22802\ttest-error:0.23580\n",
      "[124]\ttrain-error:0.22787\ttest-error:0.23575\n",
      "[125]\ttrain-error:0.22763\ttest-error:0.23558\n",
      "[126]\ttrain-error:0.22753\ttest-error:0.23556\n",
      "[127]\ttrain-error:0.22743\ttest-error:0.23545\n",
      "[128]\ttrain-error:0.22744\ttest-error:0.23550\n",
      "[129]\ttrain-error:0.22748\ttest-error:0.23554\n",
      "[130]\ttrain-error:0.22740\ttest-error:0.23547\n",
      "[131]\ttrain-error:0.22722\ttest-error:0.23538\n",
      "[132]\ttrain-error:0.22724\ttest-error:0.23540\n",
      "[133]\ttrain-error:0.22721\ttest-error:0.23559\n",
      "[134]\ttrain-error:0.22721\ttest-error:0.23549\n",
      "[135]\ttrain-error:0.22703\ttest-error:0.23549\n",
      "[136]\ttrain-error:0.22703\ttest-error:0.23536\n",
      "[137]\ttrain-error:0.22687\ttest-error:0.23517\n",
      "[138]\ttrain-error:0.22678\ttest-error:0.23497\n",
      "[139]\ttrain-error:0.22664\ttest-error:0.23513\n",
      "[140]\ttrain-error:0.22669\ttest-error:0.23511\n",
      "[141]\ttrain-error:0.22644\ttest-error:0.23501\n",
      "[142]\ttrain-error:0.22625\ttest-error:0.23505\n",
      "[143]\ttrain-error:0.22611\ttest-error:0.23501\n",
      "[144]\ttrain-error:0.22593\ttest-error:0.23490\n",
      "[145]\ttrain-error:0.22590\ttest-error:0.23480\n",
      "[146]\ttrain-error:0.22570\ttest-error:0.23476\n",
      "[147]\ttrain-error:0.22567\ttest-error:0.23487\n",
      "[148]\ttrain-error:0.22555\ttest-error:0.23469\n",
      "[149]\ttrain-error:0.22547\ttest-error:0.23466\n",
      "[150]\ttrain-error:0.22543\ttest-error:0.23467\n",
      "[151]\ttrain-error:0.22532\ttest-error:0.23464\n",
      "[152]\ttrain-error:0.22531\ttest-error:0.23455\n",
      "[153]\ttrain-error:0.22512\ttest-error:0.23444\n",
      "[154]\ttrain-error:0.22514\ttest-error:0.23428\n",
      "[155]\ttrain-error:0.22498\ttest-error:0.23436\n",
      "[156]\ttrain-error:0.22503\ttest-error:0.23439\n",
      "[157]\ttrain-error:0.22487\ttest-error:0.23434\n",
      "[158]\ttrain-error:0.22485\ttest-error:0.23441\n",
      "[159]\ttrain-error:0.22468\ttest-error:0.23421\n",
      "[160]\ttrain-error:0.22457\ttest-error:0.23423\n",
      "[161]\ttrain-error:0.22443\ttest-error:0.23432\n",
      "[162]\ttrain-error:0.22441\ttest-error:0.23421\n",
      "[163]\ttrain-error:0.22426\ttest-error:0.23418\n",
      "[164]\ttrain-error:0.22422\ttest-error:0.23397\n",
      "[165]\ttrain-error:0.22406\ttest-error:0.23413\n",
      "[166]\ttrain-error:0.22393\ttest-error:0.23388\n",
      "[167]\ttrain-error:0.22402\ttest-error:0.23386\n",
      "[168]\ttrain-error:0.22376\ttest-error:0.23372\n",
      "[169]\ttrain-error:0.22373\ttest-error:0.23361\n",
      "[170]\ttrain-error:0.22374\ttest-error:0.23370\n",
      "[171]\ttrain-error:0.22361\ttest-error:0.23370\n",
      "[172]\ttrain-error:0.22357\ttest-error:0.23360\n",
      "[173]\ttrain-error:0.22357\ttest-error:0.23353\n",
      "[174]\ttrain-error:0.22339\ttest-error:0.23356\n",
      "[175]\ttrain-error:0.22334\ttest-error:0.23356\n",
      "[176]\ttrain-error:0.22336\ttest-error:0.23353\n",
      "[177]\ttrain-error:0.22326\ttest-error:0.23335\n",
      "[178]\ttrain-error:0.22330\ttest-error:0.23315\n",
      "[179]\ttrain-error:0.22323\ttest-error:0.23317\n",
      "[180]\ttrain-error:0.22313\ttest-error:0.23303\n",
      "[181]\ttrain-error:0.22301\ttest-error:0.23298\n",
      "[182]\ttrain-error:0.22287\ttest-error:0.23284\n",
      "[183]\ttrain-error:0.22274\ttest-error:0.23305\n",
      "[184]\ttrain-error:0.22266\ttest-error:0.23305\n",
      "[185]\ttrain-error:0.22260\ttest-error:0.23301\n",
      "[186]\ttrain-error:0.22241\ttest-error:0.23317\n",
      "[187]\ttrain-error:0.22218\ttest-error:0.23278\n",
      "[188]\ttrain-error:0.22211\ttest-error:0.23277\n",
      "[189]\ttrain-error:0.22205\ttest-error:0.23262\n",
      "[190]\ttrain-error:0.22194\ttest-error:0.23270\n",
      "[191]\ttrain-error:0.22179\ttest-error:0.23264\n",
      "[192]\ttrain-error:0.22170\ttest-error:0.23266\n",
      "[193]\ttrain-error:0.22167\ttest-error:0.23255\n",
      "[194]\ttrain-error:0.22151\ttest-error:0.23247\n",
      "[195]\ttrain-error:0.22148\ttest-error:0.23245\n",
      "[196]\ttrain-error:0.22131\ttest-error:0.23250\n",
      "[197]\ttrain-error:0.22123\ttest-error:0.23248\n",
      "[198]\ttrain-error:0.22113\ttest-error:0.23247\n",
      "[199]\ttrain-error:0.22107\ttest-error:0.23232\n",
      "[200]\ttrain-error:0.22110\ttest-error:0.23227\n",
      "[201]\ttrain-error:0.22104\ttest-error:0.23227\n",
      "[202]\ttrain-error:0.22101\ttest-error:0.23215\n",
      "[203]\ttrain-error:0.22087\ttest-error:0.23236\n",
      "[204]\ttrain-error:0.22065\ttest-error:0.23243\n",
      "[205]\ttrain-error:0.22062\ttest-error:0.23236\n",
      "[206]\ttrain-error:0.22060\ttest-error:0.23232\n",
      "[207]\ttrain-error:0.22052\ttest-error:0.23218\n",
      "[208]\ttrain-error:0.22036\ttest-error:0.23215\n",
      "[209]\ttrain-error:0.22020\ttest-error:0.23217\n",
      "[210]\ttrain-error:0.21997\ttest-error:0.23204\n",
      "[211]\ttrain-error:0.22000\ttest-error:0.23194\n",
      "[212]\ttrain-error:0.21993\ttest-error:0.23202\n",
      "[213]\ttrain-error:0.21988\ttest-error:0.23217\n",
      "[214]\ttrain-error:0.21970\ttest-error:0.23190\n",
      "[215]\ttrain-error:0.21965\ttest-error:0.23185\n",
      "[216]\ttrain-error:0.21957\ttest-error:0.23174\n",
      "[217]\ttrain-error:0.21957\ttest-error:0.23176\n",
      "[218]\ttrain-error:0.21953\ttest-error:0.23176\n",
      "[219]\ttrain-error:0.21962\ttest-error:0.23160\n",
      "[220]\ttrain-error:0.21944\ttest-error:0.23169\n",
      "[221]\ttrain-error:0.21932\ttest-error:0.23156\n",
      "[222]\ttrain-error:0.21935\ttest-error:0.23162\n",
      "[223]\ttrain-error:0.21926\ttest-error:0.23162\n",
      "[224]\ttrain-error:0.21922\ttest-error:0.23164\n",
      "[225]\ttrain-error:0.21918\ttest-error:0.23171\n",
      "[226]\ttrain-error:0.21904\ttest-error:0.23151\n",
      "[227]\ttrain-error:0.21904\ttest-error:0.23155\n",
      "[228]\ttrain-error:0.21899\ttest-error:0.23156\n",
      "[229]\ttrain-error:0.21888\ttest-error:0.23162\n",
      "[230]\ttrain-error:0.21879\ttest-error:0.23149\n",
      "[231]\ttrain-error:0.21876\ttest-error:0.23149\n",
      "[232]\ttrain-error:0.21877\ttest-error:0.23151\n",
      "[233]\ttrain-error:0.21863\ttest-error:0.23144\n",
      "[234]\ttrain-error:0.21843\ttest-error:0.23132\n",
      "[235]\ttrain-error:0.21843\ttest-error:0.23132\n",
      "[236]\ttrain-error:0.21839\ttest-error:0.23125\n",
      "[237]\ttrain-error:0.21823\ttest-error:0.23139\n",
      "[238]\ttrain-error:0.21821\ttest-error:0.23132\n",
      "[239]\ttrain-error:0.21812\ttest-error:0.23128\n",
      "[240]\ttrain-error:0.21813\ttest-error:0.23137\n",
      "[241]\ttrain-error:0.21816\ttest-error:0.23134\n",
      "[242]\ttrain-error:0.21797\ttest-error:0.23144\n",
      "[243]\ttrain-error:0.21790\ttest-error:0.23144\n",
      "[244]\ttrain-error:0.21781\ttest-error:0.23135\n",
      "[245]\ttrain-error:0.21777\ttest-error:0.23121\n",
      "[246]\ttrain-error:0.21777\ttest-error:0.23125\n",
      "[247]\ttrain-error:0.21763\ttest-error:0.23125\n",
      "[248]\ttrain-error:0.21740\ttest-error:0.23121\n",
      "[249]\ttrain-error:0.21737\ttest-error:0.23126\n",
      "[250]\ttrain-error:0.21737\ttest-error:0.23132\n",
      "[251]\ttrain-error:0.21730\ttest-error:0.23112\n",
      "[252]\ttrain-error:0.21718\ttest-error:0.23107\n",
      "[253]\ttrain-error:0.21710\ttest-error:0.23105\n",
      "[254]\ttrain-error:0.21698\ttest-error:0.23100\n",
      "[255]\ttrain-error:0.21706\ttest-error:0.23105\n",
      "[256]\ttrain-error:0.21684\ttest-error:0.23102\n",
      "[257]\ttrain-error:0.21666\ttest-error:0.23098\n",
      "[258]\ttrain-error:0.21657\ttest-error:0.23095\n",
      "[259]\ttrain-error:0.21644\ttest-error:0.23095\n",
      "[260]\ttrain-error:0.21644\ttest-error:0.23093\n",
      "[261]\ttrain-error:0.21640\ttest-error:0.23089\n",
      "[262]\ttrain-error:0.21635\ttest-error:0.23087\n",
      "[263]\ttrain-error:0.21628\ttest-error:0.23082\n",
      "[264]\ttrain-error:0.21626\ttest-error:0.23091\n",
      "[265]\ttrain-error:0.21629\ttest-error:0.23056\n",
      "[266]\ttrain-error:0.21617\ttest-error:0.23042\n",
      "[267]\ttrain-error:0.21608\ttest-error:0.23042\n",
      "[268]\ttrain-error:0.21604\ttest-error:0.23038\n",
      "[269]\ttrain-error:0.21601\ttest-error:0.23040\n",
      "[270]\ttrain-error:0.21595\ttest-error:0.23045\n",
      "[271]\ttrain-error:0.21590\ttest-error:0.23047\n",
      "[272]\ttrain-error:0.21576\ttest-error:0.23042\n",
      "[273]\ttrain-error:0.21558\ttest-error:0.23031\n",
      "[274]\ttrain-error:0.21538\ttest-error:0.23042\n",
      "[275]\ttrain-error:0.21539\ttest-error:0.23038\n",
      "[276]\ttrain-error:0.21538\ttest-error:0.23031\n",
      "[277]\ttrain-error:0.21524\ttest-error:0.23022\n",
      "[278]\ttrain-error:0.21513\ttest-error:0.23019\n",
      "[279]\ttrain-error:0.21495\ttest-error:0.23033\n",
      "[280]\ttrain-error:0.21484\ttest-error:0.23029\n",
      "[281]\ttrain-error:0.21466\ttest-error:0.23022\n",
      "[282]\ttrain-error:0.21464\ttest-error:0.23015\n",
      "[283]\ttrain-error:0.21457\ttest-error:0.23010\n",
      "[284]\ttrain-error:0.21457\ttest-error:0.23015\n",
      "[285]\ttrain-error:0.21456\ttest-error:0.22999\n",
      "[286]\ttrain-error:0.21456\ttest-error:0.23001\n",
      "[287]\ttrain-error:0.21451\ttest-error:0.23001\n",
      "[288]\ttrain-error:0.21445\ttest-error:0.23004\n",
      "[289]\ttrain-error:0.21436\ttest-error:0.23006\n",
      "[290]\ttrain-error:0.21431\ttest-error:0.23006\n",
      "[291]\ttrain-error:0.21424\ttest-error:0.22987\n",
      "[292]\ttrain-error:0.21419\ttest-error:0.22969\n",
      "[293]\ttrain-error:0.21419\ttest-error:0.22973\n",
      "[294]\ttrain-error:0.21413\ttest-error:0.22973\n",
      "[295]\ttrain-error:0.21407\ttest-error:0.22967\n",
      "[296]\ttrain-error:0.21407\ttest-error:0.22962\n",
      "[297]\ttrain-error:0.21394\ttest-error:0.22953\n",
      "[298]\ttrain-error:0.21393\ttest-error:0.22969\n",
      "[299]\ttrain-error:0.21382\ttest-error:0.22983\n",
      "[300]\ttrain-error:0.21367\ttest-error:0.22996\n",
      "[301]\ttrain-error:0.21360\ttest-error:0.22983\n",
      "[302]\ttrain-error:0.21355\ttest-error:0.22978\n",
      "[303]\ttrain-error:0.21353\ttest-error:0.22978\n",
      "[304]\ttrain-error:0.21329\ttest-error:0.22976\n",
      "[305]\ttrain-error:0.21327\ttest-error:0.22962\n",
      "[306]\ttrain-error:0.21309\ttest-error:0.22964\n",
      "[307]\ttrain-error:0.21315\ttest-error:0.22960\n",
      "[308]\ttrain-error:0.21315\ttest-error:0.22955\n",
      "[309]\ttrain-error:0.21297\ttest-error:0.22967\n",
      "[310]\ttrain-error:0.21290\ttest-error:0.22959\n",
      "[311]\ttrain-error:0.21293\ttest-error:0.22943\n",
      "[312]\ttrain-error:0.21284\ttest-error:0.22953\n",
      "[313]\ttrain-error:0.21277\ttest-error:0.22950\n",
      "[314]\ttrain-error:0.21279\ttest-error:0.22960\n",
      "[315]\ttrain-error:0.21256\ttest-error:0.22962\n",
      "[316]\ttrain-error:0.21256\ttest-error:0.22955\n",
      "[317]\ttrain-error:0.21246\ttest-error:0.22946\n",
      "[318]\ttrain-error:0.21243\ttest-error:0.22946\n",
      "[319]\ttrain-error:0.21241\ttest-error:0.22943\n",
      "[320]\ttrain-error:0.21225\ttest-error:0.22941\n",
      "[321]\ttrain-error:0.21210\ttest-error:0.22934\n",
      "[322]\ttrain-error:0.21219\ttest-error:0.22925\n",
      "[323]\ttrain-error:0.21225\ttest-error:0.22932\n",
      "[324]\ttrain-error:0.21222\ttest-error:0.22928\n",
      "[325]\ttrain-error:0.21218\ttest-error:0.22927\n",
      "[326]\ttrain-error:0.21210\ttest-error:0.22920\n",
      "[327]\ttrain-error:0.21205\ttest-error:0.22923\n",
      "[328]\ttrain-error:0.21194\ttest-error:0.22934\n",
      "[329]\ttrain-error:0.21189\ttest-error:0.22923\n",
      "[330]\ttrain-error:0.21188\ttest-error:0.22934\n",
      "[331]\ttrain-error:0.21188\ttest-error:0.22927\n",
      "[332]\ttrain-error:0.21179\ttest-error:0.22916\n",
      "[333]\ttrain-error:0.21169\ttest-error:0.22909\n",
      "[334]\ttrain-error:0.21163\ttest-error:0.22907\n",
      "[335]\ttrain-error:0.21161\ttest-error:0.22906\n",
      "[336]\ttrain-error:0.21151\ttest-error:0.22906\n",
      "[337]\ttrain-error:0.21148\ttest-error:0.22900\n",
      "[338]\ttrain-error:0.21151\ttest-error:0.22904\n",
      "[339]\ttrain-error:0.21140\ttest-error:0.22906\n",
      "[340]\ttrain-error:0.21130\ttest-error:0.22904\n",
      "[341]\ttrain-error:0.21117\ttest-error:0.22911\n",
      "[342]\ttrain-error:0.21116\ttest-error:0.22907\n",
      "[343]\ttrain-error:0.21111\ttest-error:0.22914\n",
      "[344]\ttrain-error:0.21099\ttest-error:0.22907\n",
      "[345]\ttrain-error:0.21095\ttest-error:0.22907\n",
      "[346]\ttrain-error:0.21083\ttest-error:0.22911\n",
      "[347]\ttrain-error:0.21080\ttest-error:0.22916\n",
      "[348]\ttrain-error:0.21077\ttest-error:0.22907\n",
      "[349]\ttrain-error:0.21078\ttest-error:0.22911\n",
      "[350]\ttrain-error:0.21065\ttest-error:0.22891\n",
      "[351]\ttrain-error:0.21058\ttest-error:0.22888\n",
      "[352]\ttrain-error:0.21052\ttest-error:0.22879\n",
      "[353]\ttrain-error:0.21045\ttest-error:0.22886\n",
      "[354]\ttrain-error:0.21032\ttest-error:0.22886\n",
      "[355]\ttrain-error:0.21033\ttest-error:0.22879\n",
      "[356]\ttrain-error:0.21019\ttest-error:0.22847\n",
      "[357]\ttrain-error:0.21023\ttest-error:0.22854\n",
      "[358]\ttrain-error:0.21012\ttest-error:0.22847\n",
      "[359]\ttrain-error:0.21009\ttest-error:0.22865\n",
      "[360]\ttrain-error:0.21010\ttest-error:0.22849\n",
      "[361]\ttrain-error:0.21009\ttest-error:0.22853\n",
      "[362]\ttrain-error:0.21006\ttest-error:0.22868\n",
      "[363]\ttrain-error:0.20999\ttest-error:0.22875\n",
      "[364]\ttrain-error:0.20991\ttest-error:0.22868\n",
      "[365]\ttrain-error:0.20977\ttest-error:0.22845\n",
      "[366]\ttrain-error:0.20975\ttest-error:0.22847\n",
      "[367]\ttrain-error:0.20965\ttest-error:0.22844\n",
      "[368]\ttrain-error:0.20965\ttest-error:0.22844\n",
      "[369]\ttrain-error:0.20960\ttest-error:0.22838\n",
      "[370]\ttrain-error:0.20960\ttest-error:0.22845\n",
      "[371]\ttrain-error:0.20958\ttest-error:0.22853\n",
      "[372]\ttrain-error:0.20962\ttest-error:0.22849\n",
      "[373]\ttrain-error:0.20966\ttest-error:0.22853\n",
      "[374]\ttrain-error:0.20958\ttest-error:0.22849\n",
      "[375]\ttrain-error:0.20947\ttest-error:0.22863\n",
      "[376]\ttrain-error:0.20947\ttest-error:0.22858\n",
      "[377]\ttrain-error:0.20938\ttest-error:0.22860\n",
      "[378]\ttrain-error:0.20935\ttest-error:0.22868\n",
      "[379]\ttrain-error:0.20936\ttest-error:0.22853\n",
      "[380]\ttrain-error:0.20935\ttest-error:0.22844\n",
      "[381]\ttrain-error:0.20933\ttest-error:0.22838\n",
      "[382]\ttrain-error:0.20920\ttest-error:0.22831\n",
      "[383]\ttrain-error:0.20910\ttest-error:0.22842\n",
      "[384]\ttrain-error:0.20906\ttest-error:0.22833\n",
      "[385]\ttrain-error:0.20904\ttest-error:0.22831\n",
      "[386]\ttrain-error:0.20904\ttest-error:0.22844\n",
      "[387]\ttrain-error:0.20888\ttest-error:0.22853\n",
      "[388]\ttrain-error:0.20886\ttest-error:0.22847\n",
      "[389]\ttrain-error:0.20889\ttest-error:0.22842\n",
      "[390]\ttrain-error:0.20881\ttest-error:0.22840\n",
      "[391]\ttrain-error:0.20873\ttest-error:0.22826\n",
      "[392]\ttrain-error:0.20859\ttest-error:0.22835\n",
      "[393]\ttrain-error:0.20858\ttest-error:0.22830\n",
      "[394]\ttrain-error:0.20856\ttest-error:0.22828\n",
      "[395]\ttrain-error:0.20854\ttest-error:0.22835\n",
      "[396]\ttrain-error:0.20852\ttest-error:0.22831\n",
      "[397]\ttrain-error:0.20840\ttest-error:0.22824\n",
      "[398]\ttrain-error:0.20828\ttest-error:0.22830\n",
      "[399]\ttrain-error:0.20824\ttest-error:0.22821\n",
      "[400]\ttrain-error:0.20828\ttest-error:0.22823\n",
      "[401]\ttrain-error:0.20811\ttest-error:0.22814\n",
      "[402]\ttrain-error:0.20811\ttest-error:0.22812\n",
      "[403]\ttrain-error:0.20805\ttest-error:0.22810\n",
      "[404]\ttrain-error:0.20800\ttest-error:0.22805\n",
      "[405]\ttrain-error:0.20801\ttest-error:0.22792\n",
      "[406]\ttrain-error:0.20792\ttest-error:0.22796\n",
      "[407]\ttrain-error:0.20768\ttest-error:0.22801\n",
      "[408]\ttrain-error:0.20761\ttest-error:0.22791\n",
      "[409]\ttrain-error:0.20763\ttest-error:0.22807\n",
      "[410]\ttrain-error:0.20743\ttest-error:0.22803\n",
      "[411]\ttrain-error:0.20745\ttest-error:0.22808\n",
      "[412]\ttrain-error:0.20734\ttest-error:0.22798\n",
      "[413]\ttrain-error:0.20739\ttest-error:0.22805\n",
      "[414]\ttrain-error:0.20733\ttest-error:0.22808\n",
      "[415]\ttrain-error:0.20728\ttest-error:0.22805\n",
      "[416]\ttrain-error:0.20726\ttest-error:0.22800\n",
      "[417]\ttrain-error:0.20721\ttest-error:0.22787\n",
      "[418]\ttrain-error:0.20719\ttest-error:0.22801\n",
      "[419]\ttrain-error:0.20713\ttest-error:0.22810\n",
      "[420]\ttrain-error:0.20713\ttest-error:0.22808\n",
      "[421]\ttrain-error:0.20701\ttest-error:0.22808\n",
      "[422]\ttrain-error:0.20694\ttest-error:0.22805\n",
      "[423]\ttrain-error:0.20691\ttest-error:0.22812\n",
      "[424]\ttrain-error:0.20681\ttest-error:0.22814\n",
      "[425]\ttrain-error:0.20678\ttest-error:0.22801\n",
      "[426]\ttrain-error:0.20681\ttest-error:0.22792\n",
      "[427]\ttrain-error:0.20682\ttest-error:0.22789\n",
      "[428]\ttrain-error:0.20675\ttest-error:0.22789\n",
      "[429]\ttrain-error:0.20675\ttest-error:0.22791\n",
      "[430]\ttrain-error:0.20663\ttest-error:0.22798\n",
      "[431]\ttrain-error:0.20655\ttest-error:0.22785\n",
      "[432]\ttrain-error:0.20634\ttest-error:0.22782\n",
      "[433]\ttrain-error:0.20640\ttest-error:0.22789\n",
      "[434]\ttrain-error:0.20639\ttest-error:0.22784\n",
      "[435]\ttrain-error:0.20629\ttest-error:0.22777\n",
      "[436]\ttrain-error:0.20605\ttest-error:0.22773\n",
      "[437]\ttrain-error:0.20597\ttest-error:0.22784\n",
      "[438]\ttrain-error:0.20600\ttest-error:0.22787\n",
      "[439]\ttrain-error:0.20591\ttest-error:0.22787\n",
      "[440]\ttrain-error:0.20589\ttest-error:0.22784\n",
      "[441]\ttrain-error:0.20580\ttest-error:0.22785\n",
      "[442]\ttrain-error:0.20570\ttest-error:0.22787\n",
      "[443]\ttrain-error:0.20564\ttest-error:0.22789\n",
      "[444]\ttrain-error:0.20557\ttest-error:0.22784\n",
      "[445]\ttrain-error:0.20555\ttest-error:0.22773\n",
      "[446]\ttrain-error:0.20550\ttest-error:0.22773\n",
      "[447]\ttrain-error:0.20547\ttest-error:0.22777\n",
      "[448]\ttrain-error:0.20546\ttest-error:0.22775\n",
      "[449]\ttrain-error:0.20538\ttest-error:0.22784\n",
      "[450]\ttrain-error:0.20526\ttest-error:0.22768\n",
      "[451]\ttrain-error:0.20514\ttest-error:0.22771\n",
      "[452]\ttrain-error:0.20503\ttest-error:0.22761\n",
      "[453]\ttrain-error:0.20497\ttest-error:0.22771\n",
      "[454]\ttrain-error:0.20498\ttest-error:0.22771\n",
      "[455]\ttrain-error:0.20491\ttest-error:0.22764\n",
      "[456]\ttrain-error:0.20493\ttest-error:0.22755\n",
      "[457]\ttrain-error:0.20475\ttest-error:0.22757\n",
      "[458]\ttrain-error:0.20478\ttest-error:0.22759\n",
      "[459]\ttrain-error:0.20479\ttest-error:0.22750\n",
      "[460]\ttrain-error:0.20472\ttest-error:0.22762\n",
      "[461]\ttrain-error:0.20464\ttest-error:0.22759\n",
      "[462]\ttrain-error:0.20459\ttest-error:0.22752\n",
      "[463]\ttrain-error:0.20450\ttest-error:0.22754\n",
      "[464]\ttrain-error:0.20452\ttest-error:0.22748\n",
      "[465]\ttrain-error:0.20447\ttest-error:0.22747\n",
      "[466]\ttrain-error:0.20437\ttest-error:0.22740\n",
      "[467]\ttrain-error:0.20441\ttest-error:0.22734\n",
      "[468]\ttrain-error:0.20428\ttest-error:0.22752\n",
      "[469]\ttrain-error:0.20433\ttest-error:0.22747\n",
      "[470]\ttrain-error:0.20439\ttest-error:0.22740\n",
      "[471]\ttrain-error:0.20428\ttest-error:0.22738\n",
      "[472]\ttrain-error:0.20417\ttest-error:0.22738\n",
      "[473]\ttrain-error:0.20420\ttest-error:0.22743\n",
      "[474]\ttrain-error:0.20407\ttest-error:0.22757\n",
      "[475]\ttrain-error:0.20406\ttest-error:0.22752\n",
      "[476]\ttrain-error:0.20392\ttest-error:0.22740\n",
      "[477]\ttrain-error:0.20388\ttest-error:0.22741\n",
      "[478]\ttrain-error:0.20382\ttest-error:0.22747\n",
      "[479]\ttrain-error:0.20377\ttest-error:0.22748\n",
      "[480]\ttrain-error:0.20372\ttest-error:0.22725\n",
      "[481]\ttrain-error:0.20362\ttest-error:0.22727\n",
      "[482]\ttrain-error:0.20357\ttest-error:0.22715\n",
      "[483]\ttrain-error:0.20340\ttest-error:0.22709\n",
      "[484]\ttrain-error:0.20335\ttest-error:0.22725\n",
      "[485]\ttrain-error:0.20332\ttest-error:0.22729\n",
      "[486]\ttrain-error:0.20333\ttest-error:0.22731\n",
      "[487]\ttrain-error:0.20329\ttest-error:0.22731\n",
      "[488]\ttrain-error:0.20324\ttest-error:0.22732\n",
      "[489]\ttrain-error:0.20325\ttest-error:0.22715\n",
      "[490]\ttrain-error:0.20320\ttest-error:0.22718\n",
      "[491]\ttrain-error:0.20317\ttest-error:0.22720\n",
      "[492]\ttrain-error:0.20308\ttest-error:0.22711\n",
      "[493]\ttrain-error:0.20299\ttest-error:0.22713\n",
      "[494]\ttrain-error:0.20293\ttest-error:0.22717\n",
      "[495]\ttrain-error:0.20285\ttest-error:0.22697\n",
      "[496]\ttrain-error:0.20284\ttest-error:0.22702\n",
      "[497]\ttrain-error:0.20283\ttest-error:0.22704\n",
      "[498]\ttrain-error:0.20281\ttest-error:0.22709\n",
      "[499]\ttrain-error:0.20269\ttest-error:0.22729\n"
     ]
    }
   ],
   "source": [
    "dtrain, dtest = xgb.DMatrix(X_train, y_train, feature_names=FEATS), xgb.DMatrix(X_test, y_test, feature_names=FEATS)\n",
    "\n",
    "ROUNDS = 500\n",
    "EVAL_LIST = [(dtrain, \"train\"),(dtest, \"test\")]\n",
    "\n",
    "xgb_model = xgb.train(params,dtrain,ROUNDS,EVAL_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_P</th>\n",
       "      <td>170.013235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT_METHOD_NonDD</th>\n",
       "      <td>47.193247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOME_EM_ADDON_POST_REN_Y</th>\n",
       "      <td>26.109552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD_BUILDINGS_Y</th>\n",
       "      <td>24.743001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KEYCARE_ADDON_PRE_REN_Y</th>\n",
       "      <td>22.145358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX_DAYS_UNOCC</th>\n",
       "      <td>21.692534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP1_ADDON_POST_REN_Y</th>\n",
       "      <td>20.775646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP2_ADDON_POST_REN_Y</th>\n",
       "      <td>20.063199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEGAL_ADDON_POST_REN_Y</th>\n",
       "      <td>18.202539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT_METHOD_PureDD</th>\n",
       "      <td>17.556776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP3_ADDON_POST_REN_Y</th>\n",
       "      <td>15.941809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUM_INSURED_BUILDINGS</th>\n",
       "      <td>15.675539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARDEN_ADDON_PRE_REN_Y</th>\n",
       "      <td>14.565703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KEYCARE_ADDON_POST_REN_Y</th>\n",
       "      <td>13.675880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCC_STATUS_LP</th>\n",
       "      <td>12.632733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARDEN_ADDON_POST_REN_Y</th>\n",
       "      <td>12.277981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOME_EM_ADDON_PRE_REN_Y</th>\n",
       "      <td>11.742306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTA_FLAG_Y</th>\n",
       "      <td>10.789477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_2.0</th>\n",
       "      <td>9.435106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_O</th>\n",
       "      <td>9.230607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_22.0</th>\n",
       "      <td>8.713453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCD_GRANTED_YEARS_B</th>\n",
       "      <td>8.266899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUBSIDENCE_Y</th>\n",
       "      <td>8.204736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cover_length</th>\n",
       "      <td>8.037479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCC_STATUS_PH</th>\n",
       "      <td>7.679981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_2.0</th>\n",
       "      <td>7.634772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_51.0</th>\n",
       "      <td>7.634436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUM_INSURED_CONTENTS</th>\n",
       "      <td>7.485276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUILDINGS_COVER_Y</th>\n",
       "      <td>7.424712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_RATED_AREA_C_imputed</th>\n",
       "      <td>7.068925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_RATED_AREA_B_imputed</th>\n",
       "      <td>6.689967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCD_GRANTED_YEARS_C</th>\n",
       "      <td>6.622818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAFE_INSTALLED_Y</th>\n",
       "      <td>6.621982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTA_FAP_imputed</th>\n",
       "      <td>6.340095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_16.0</th>\n",
       "      <td>6.281836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNSPEC_HRP_PREM</th>\n",
       "      <td>6.224119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_4.0</th>\n",
       "      <td>6.172431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCC_STATUS_UN</th>\n",
       "      <td>6.160243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_H</th>\n",
       "      <td>6.137361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOODING_Y</th>\n",
       "      <td>6.006965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_17.0</th>\n",
       "      <td>5.977949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAST_ANN_PREM_GROSS</th>\n",
       "      <td>5.877564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPEC_ITEM_PREM</th>\n",
       "      <td>5.775829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUS_USE_Y</th>\n",
       "      <td>5.761504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_18.0</th>\n",
       "      <td>5.718065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_D</th>\n",
       "      <td>5.690293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_32.0</th>\n",
       "      <td>5.669324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTA_APRP_imputed</th>\n",
       "      <td>5.602118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP2_ADDON_PRE_REN_Y</th>\n",
       "      <td>5.572457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPEC_SUM_INSURED</th>\n",
       "      <td>5.565167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_7.0</th>\n",
       "      <td>5.493985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLAIM3YEARS_Y</th>\n",
       "      <td>5.458455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_45.0</th>\n",
       "      <td>5.301980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_53.0</th>\n",
       "      <td>5.259304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_U</th>\n",
       "      <td>5.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_M</th>\n",
       "      <td>5.104878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_S</th>\n",
       "      <td>5.098258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_age</th>\n",
       "      <td>5.092778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_W</th>\n",
       "      <td>5.069282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_26.0</th>\n",
       "      <td>5.013073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_7.0</th>\n",
       "      <td>4.978121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_S</th>\n",
       "      <td>4.906850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_N</th>\n",
       "      <td>4.894169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_9.0</th>\n",
       "      <td>4.877387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_52.0</th>\n",
       "      <td>4.829099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>4.823992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_C</th>\n",
       "      <td>4.771094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_14.0</th>\n",
       "      <td>4.759505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEDROOMS</th>\n",
       "      <td>4.733171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_25.0</th>\n",
       "      <td>4.654037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_19.0</th>\n",
       "      <td>4.643327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_18.0</th>\n",
       "      <td>4.640873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_E</th>\n",
       "      <td>4.625132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APPR_ALARM_Y</th>\n",
       "      <td>4.612885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_12.0</th>\n",
       "      <td>4.402632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_3.0</th>\n",
       "      <td>4.378780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_48.0</th>\n",
       "      <td>4.291513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APPR_LOCKS_Y</th>\n",
       "      <td>4.126195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_R</th>\n",
       "      <td>4.076524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEC_DISC_REQ_Y</th>\n",
       "      <td>4.060985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_13.0</th>\n",
       "      <td>4.024259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_8.0</th>\n",
       "      <td>4.006247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_SEX_M</th>\n",
       "      <td>3.958018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_10.0</th>\n",
       "      <td>3.947126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_47.0</th>\n",
       "      <td>3.913844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEIGH_WATCH_Y</th>\n",
       "      <td>3.880506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "P1_MAR_STATUS_P            170.013235\n",
       "PAYMENT_METHOD_NonDD        47.193247\n",
       "HOME_EM_ADDON_POST_REN_Y    26.109552\n",
       "AD_BUILDINGS_Y              24.743001\n",
       "KEYCARE_ADDON_PRE_REN_Y     22.145358\n",
       "MAX_DAYS_UNOCC              21.692534\n",
       "HP1_ADDON_POST_REN_Y        20.775646\n",
       "HP2_ADDON_POST_REN_Y        20.063199\n",
       "LEGAL_ADDON_POST_REN_Y      18.202539\n",
       "PAYMENT_METHOD_PureDD       17.556776\n",
       "HP3_ADDON_POST_REN_Y        15.941809\n",
       "SUM_INSURED_BUILDINGS       15.675539\n",
       "GARDEN_ADDON_PRE_REN_Y      14.565703\n",
       "KEYCARE_ADDON_POST_REN_Y    13.675880\n",
       "OCC_STATUS_LP               12.632733\n",
       "GARDEN_ADDON_POST_REN_Y     12.277981\n",
       "HOME_EM_ADDON_PRE_REN_Y     11.742306\n",
       "MTA_FLAG_Y                  10.789477\n",
       "PROP_TYPE_2.0                9.435106\n",
       "P1_MAR_STATUS_O              9.230607\n",
       "PROP_TYPE_22.0               8.713453\n",
       "NCD_GRANTED_YEARS_B          8.266899\n",
       "SUBSIDENCE_Y                 8.204736\n",
       "cover_length                 8.037479\n",
       "OCC_STATUS_PH                7.679981\n",
       "OWNERSHIP_TYPE_2.0           7.634772\n",
       "PROP_TYPE_51.0               7.634436\n",
       "SUM_INSURED_CONTENTS         7.485276\n",
       "BUILDINGS_COVER_Y            7.424712\n",
       "RISK_RATED_AREA_C_imputed    7.068925\n",
       "RISK_RATED_AREA_B_imputed    6.689967\n",
       "NCD_GRANTED_YEARS_C          6.622818\n",
       "SAFE_INSTALLED_Y             6.621982\n",
       "MTA_FAP_imputed              6.340095\n",
       "PROP_TYPE_16.0               6.281836\n",
       "UNSPEC_HRP_PREM              6.224119\n",
       "PROP_TYPE_4.0                6.172431\n",
       "OCC_STATUS_UN                6.160243\n",
       "P1_EMP_STATUS_H              6.137361\n",
       "FLOODING_Y                   6.006965\n",
       "PROP_TYPE_17.0               5.977949\n",
       "LAST_ANN_PREM_GROSS          5.877564\n",
       "SPEC_ITEM_PREM               5.775829\n",
       "BUS_USE_Y                    5.761504\n",
       "PROP_TYPE_18.0               5.718065\n",
       "P1_MAR_STATUS_D              5.690293\n",
       "PROP_TYPE_32.0               5.669324\n",
       "MTA_APRP_imputed             5.602118\n",
       "HP2_ADDON_PRE_REN_Y          5.572457\n",
       "SPEC_SUM_INSURED             5.565167\n",
       "OWNERSHIP_TYPE_7.0           5.493985\n",
       "CLAIM3YEARS_Y                5.458455\n",
       "PROP_TYPE_45.0               5.301980\n",
       "PROP_TYPE_53.0               5.259304\n",
       "P1_EMP_STATUS_U              5.259000\n",
       "P1_MAR_STATUS_M              5.104878\n",
       "P1_EMP_STATUS_S              5.098258\n",
       "property_age                 5.092778\n",
       "P1_MAR_STATUS_W              5.069282\n",
       "PROP_TYPE_26.0               5.013073\n",
       "PROP_TYPE_7.0                4.978121\n",
       "P1_MAR_STATUS_S              4.906850\n",
       "P1_EMP_STATUS_N              4.894169\n",
       "PROP_TYPE_9.0                4.877387\n",
       "PROP_TYPE_52.0               4.829099\n",
       "age                          4.823992\n",
       "P1_MAR_STATUS_C              4.771094\n",
       "OWNERSHIP_TYPE_14.0          4.759505\n",
       "BEDROOMS                     4.733171\n",
       "PROP_TYPE_25.0               4.654037\n",
       "PROP_TYPE_19.0               4.643327\n",
       "OWNERSHIP_TYPE_18.0          4.640873\n",
       "P1_EMP_STATUS_E              4.625132\n",
       "APPR_ALARM_Y                 4.612885\n",
       "OWNERSHIP_TYPE_12.0          4.402632\n",
       "OWNERSHIP_TYPE_3.0           4.378780\n",
       "PROP_TYPE_48.0               4.291513\n",
       "APPR_LOCKS_Y                 4.126195\n",
       "P1_EMP_STATUS_R              4.076524\n",
       "SEC_DISC_REQ_Y               4.060985\n",
       "OWNERSHIP_TYPE_13.0          4.024259\n",
       "OWNERSHIP_TYPE_8.0           4.006247\n",
       "P1_SEX_M                     3.958018\n",
       "PROP_TYPE_10.0               3.947126\n",
       "PROP_TYPE_47.0               3.913844\n",
       "NEIGH_WATCH_Y                3.880506"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain = pd.DataFrame.from_dict(xgb_model.get_score(importance_type=\"gain\"),orient=\"index\").sort_values(0,ascending=False)\n",
    "gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_FEATS = gain.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.24889\ttest-error:0.25142\n",
      "[1]\ttrain-error:0.24546\ttest-error:0.24773\n",
      "[2]\ttrain-error:0.24406\ttest-error:0.24679\n",
      "[3]\ttrain-error:0.24407\ttest-error:0.24580\n",
      "[4]\ttrain-error:0.24280\ttest-error:0.24538\n",
      "[5]\ttrain-error:0.24268\ttest-error:0.24591\n",
      "[6]\ttrain-error:0.24265\ttest-error:0.24526\n",
      "[7]\ttrain-error:0.24255\ttest-error:0.24550\n",
      "[8]\ttrain-error:0.24236\ttest-error:0.24549\n",
      "[9]\ttrain-error:0.24181\ttest-error:0.24462\n",
      "[10]\ttrain-error:0.24188\ttest-error:0.24482\n",
      "[11]\ttrain-error:0.24172\ttest-error:0.24554\n",
      "[12]\ttrain-error:0.24172\ttest-error:0.24503\n",
      "[13]\ttrain-error:0.24145\ttest-error:0.24455\n",
      "[14]\ttrain-error:0.24157\ttest-error:0.24455\n",
      "[15]\ttrain-error:0.24150\ttest-error:0.24466\n",
      "[16]\ttrain-error:0.24161\ttest-error:0.24476\n",
      "[17]\ttrain-error:0.24144\ttest-error:0.24488\n",
      "[18]\ttrain-error:0.24145\ttest-error:0.24469\n",
      "[19]\ttrain-error:0.24135\ttest-error:0.24476\n",
      "[20]\ttrain-error:0.24157\ttest-error:0.24458\n",
      "[21]\ttrain-error:0.24122\ttest-error:0.24467\n",
      "[22]\ttrain-error:0.24119\ttest-error:0.24462\n",
      "[23]\ttrain-error:0.24118\ttest-error:0.24448\n",
      "[24]\ttrain-error:0.24068\ttest-error:0.24446\n",
      "[25]\ttrain-error:0.24060\ttest-error:0.24423\n",
      "[26]\ttrain-error:0.24061\ttest-error:0.24423\n",
      "[27]\ttrain-error:0.24052\ttest-error:0.24409\n",
      "[28]\ttrain-error:0.24030\ttest-error:0.24391\n",
      "[29]\ttrain-error:0.24035\ttest-error:0.24388\n",
      "[30]\ttrain-error:0.24002\ttest-error:0.24405\n",
      "[31]\ttrain-error:0.23972\ttest-error:0.24351\n",
      "[32]\ttrain-error:0.23946\ttest-error:0.24328\n",
      "[33]\ttrain-error:0.23922\ttest-error:0.24299\n",
      "[34]\ttrain-error:0.23887\ttest-error:0.24312\n",
      "[35]\ttrain-error:0.23859\ttest-error:0.24282\n",
      "[36]\ttrain-error:0.23824\ttest-error:0.24282\n",
      "[37]\ttrain-error:0.23847\ttest-error:0.24269\n",
      "[38]\ttrain-error:0.23833\ttest-error:0.24262\n",
      "[39]\ttrain-error:0.23818\ttest-error:0.24229\n",
      "[40]\ttrain-error:0.23786\ttest-error:0.24259\n",
      "[41]\ttrain-error:0.23787\ttest-error:0.24243\n",
      "[42]\ttrain-error:0.23763\ttest-error:0.24218\n",
      "[43]\ttrain-error:0.23761\ttest-error:0.24213\n",
      "[44]\ttrain-error:0.23748\ttest-error:0.24204\n",
      "[45]\ttrain-error:0.23737\ttest-error:0.24192\n",
      "[46]\ttrain-error:0.23709\ttest-error:0.24201\n",
      "[47]\ttrain-error:0.23703\ttest-error:0.24213\n",
      "[48]\ttrain-error:0.23681\ttest-error:0.24199\n",
      "[49]\ttrain-error:0.23682\ttest-error:0.24199\n",
      "[50]\ttrain-error:0.23658\ttest-error:0.24172\n",
      "[51]\ttrain-error:0.23648\ttest-error:0.24155\n",
      "[52]\ttrain-error:0.23628\ttest-error:0.24133\n",
      "[53]\ttrain-error:0.23608\ttest-error:0.24128\n",
      "[54]\ttrain-error:0.23597\ttest-error:0.24114\n",
      "[55]\ttrain-error:0.23597\ttest-error:0.24105\n",
      "[56]\ttrain-error:0.23570\ttest-error:0.24107\n",
      "[57]\ttrain-error:0.23583\ttest-error:0.24080\n",
      "[58]\ttrain-error:0.23577\ttest-error:0.24089\n",
      "[59]\ttrain-error:0.23555\ttest-error:0.24072\n",
      "[60]\ttrain-error:0.23542\ttest-error:0.24066\n",
      "[61]\ttrain-error:0.23531\ttest-error:0.24070\n",
      "[62]\ttrain-error:0.23518\ttest-error:0.24079\n",
      "[63]\ttrain-error:0.23496\ttest-error:0.24066\n",
      "[64]\ttrain-error:0.23503\ttest-error:0.24064\n",
      "[65]\ttrain-error:0.23503\ttest-error:0.24068\n",
      "[66]\ttrain-error:0.23493\ttest-error:0.24056\n",
      "[67]\ttrain-error:0.23484\ttest-error:0.24049\n",
      "[68]\ttrain-error:0.23484\ttest-error:0.24029\n",
      "[69]\ttrain-error:0.23487\ttest-error:0.24001\n",
      "[70]\ttrain-error:0.23472\ttest-error:0.24019\n",
      "[71]\ttrain-error:0.23456\ttest-error:0.24008\n",
      "[72]\ttrain-error:0.23432\ttest-error:0.23974\n",
      "[73]\ttrain-error:0.23418\ttest-error:0.23985\n",
      "[74]\ttrain-error:0.23413\ttest-error:0.23973\n",
      "[75]\ttrain-error:0.23398\ttest-error:0.23958\n",
      "[76]\ttrain-error:0.23381\ttest-error:0.23953\n",
      "[77]\ttrain-error:0.23364\ttest-error:0.23953\n",
      "[78]\ttrain-error:0.23333\ttest-error:0.23955\n",
      "[79]\ttrain-error:0.23320\ttest-error:0.23953\n",
      "[80]\ttrain-error:0.23289\ttest-error:0.23927\n",
      "[81]\ttrain-error:0.23267\ttest-error:0.23920\n",
      "[82]\ttrain-error:0.23247\ttest-error:0.23904\n",
      "[83]\ttrain-error:0.23214\ttest-error:0.23877\n",
      "[84]\ttrain-error:0.23204\ttest-error:0.23888\n",
      "[85]\ttrain-error:0.23193\ttest-error:0.23867\n",
      "[86]\ttrain-error:0.23203\ttest-error:0.23861\n",
      "[87]\ttrain-error:0.23175\ttest-error:0.23865\n",
      "[88]\ttrain-error:0.23175\ttest-error:0.23865\n",
      "[89]\ttrain-error:0.23160\ttest-error:0.23852\n",
      "[90]\ttrain-error:0.23151\ttest-error:0.23833\n",
      "[91]\ttrain-error:0.23128\ttest-error:0.23833\n",
      "[92]\ttrain-error:0.23130\ttest-error:0.23845\n",
      "[93]\ttrain-error:0.23101\ttest-error:0.23830\n",
      "[94]\ttrain-error:0.23080\ttest-error:0.23821\n",
      "[95]\ttrain-error:0.23071\ttest-error:0.23794\n",
      "[96]\ttrain-error:0.23067\ttest-error:0.23798\n",
      "[97]\ttrain-error:0.23062\ttest-error:0.23782\n",
      "[98]\ttrain-error:0.23064\ttest-error:0.23780\n",
      "[99]\ttrain-error:0.23057\ttest-error:0.23769\n",
      "[100]\ttrain-error:0.23037\ttest-error:0.23757\n",
      "[101]\ttrain-error:0.23032\ttest-error:0.23757\n",
      "[102]\ttrain-error:0.23021\ttest-error:0.23748\n",
      "[103]\ttrain-error:0.23009\ttest-error:0.23768\n",
      "[104]\ttrain-error:0.23009\ttest-error:0.23769\n",
      "[105]\ttrain-error:0.23000\ttest-error:0.23759\n",
      "[106]\ttrain-error:0.23004\ttest-error:0.23743\n",
      "[107]\ttrain-error:0.22997\ttest-error:0.23750\n",
      "[108]\ttrain-error:0.22966\ttest-error:0.23718\n",
      "[109]\ttrain-error:0.22970\ttest-error:0.23731\n",
      "[110]\ttrain-error:0.22940\ttest-error:0.23709\n",
      "[111]\ttrain-error:0.22929\ttest-error:0.23692\n",
      "[112]\ttrain-error:0.22921\ttest-error:0.23697\n",
      "[113]\ttrain-error:0.22925\ttest-error:0.23694\n",
      "[114]\ttrain-error:0.22911\ttest-error:0.23672\n",
      "[115]\ttrain-error:0.22912\ttest-error:0.23669\n",
      "[116]\ttrain-error:0.22895\ttest-error:0.23662\n",
      "[117]\ttrain-error:0.22878\ttest-error:0.23641\n",
      "[118]\ttrain-error:0.22858\ttest-error:0.23614\n",
      "[119]\ttrain-error:0.22851\ttest-error:0.23616\n",
      "[120]\ttrain-error:0.22843\ttest-error:0.23607\n",
      "[121]\ttrain-error:0.22839\ttest-error:0.23596\n",
      "[122]\ttrain-error:0.22813\ttest-error:0.23580\n",
      "[123]\ttrain-error:0.22802\ttest-error:0.23580\n",
      "[124]\ttrain-error:0.22787\ttest-error:0.23575\n",
      "[125]\ttrain-error:0.22763\ttest-error:0.23558\n",
      "[126]\ttrain-error:0.22753\ttest-error:0.23556\n",
      "[127]\ttrain-error:0.22743\ttest-error:0.23545\n",
      "[128]\ttrain-error:0.22744\ttest-error:0.23550\n",
      "[129]\ttrain-error:0.22748\ttest-error:0.23554\n",
      "[130]\ttrain-error:0.22740\ttest-error:0.23547\n",
      "[131]\ttrain-error:0.22722\ttest-error:0.23538\n",
      "[132]\ttrain-error:0.22724\ttest-error:0.23540\n",
      "[133]\ttrain-error:0.22721\ttest-error:0.23559\n",
      "[134]\ttrain-error:0.22721\ttest-error:0.23549\n",
      "[135]\ttrain-error:0.22703\ttest-error:0.23549\n",
      "[136]\ttrain-error:0.22703\ttest-error:0.23536\n",
      "[137]\ttrain-error:0.22687\ttest-error:0.23517\n",
      "[138]\ttrain-error:0.22678\ttest-error:0.23497\n",
      "[139]\ttrain-error:0.22664\ttest-error:0.23513\n",
      "[140]\ttrain-error:0.22669\ttest-error:0.23511\n",
      "[141]\ttrain-error:0.22644\ttest-error:0.23501\n",
      "[142]\ttrain-error:0.22625\ttest-error:0.23505\n",
      "[143]\ttrain-error:0.22611\ttest-error:0.23501\n",
      "[144]\ttrain-error:0.22593\ttest-error:0.23490\n",
      "[145]\ttrain-error:0.22590\ttest-error:0.23480\n",
      "[146]\ttrain-error:0.22570\ttest-error:0.23476\n",
      "[147]\ttrain-error:0.22567\ttest-error:0.23487\n",
      "[148]\ttrain-error:0.22555\ttest-error:0.23469\n",
      "[149]\ttrain-error:0.22547\ttest-error:0.23466\n",
      "[150]\ttrain-error:0.22543\ttest-error:0.23467\n",
      "[151]\ttrain-error:0.22532\ttest-error:0.23464\n",
      "[152]\ttrain-error:0.22531\ttest-error:0.23455\n",
      "[153]\ttrain-error:0.22512\ttest-error:0.23444\n",
      "[154]\ttrain-error:0.22514\ttest-error:0.23428\n",
      "[155]\ttrain-error:0.22498\ttest-error:0.23436\n",
      "[156]\ttrain-error:0.22503\ttest-error:0.23439\n",
      "[157]\ttrain-error:0.22487\ttest-error:0.23434\n",
      "[158]\ttrain-error:0.22485\ttest-error:0.23441\n",
      "[159]\ttrain-error:0.22468\ttest-error:0.23421\n",
      "[160]\ttrain-error:0.22457\ttest-error:0.23423\n",
      "[161]\ttrain-error:0.22443\ttest-error:0.23432\n",
      "[162]\ttrain-error:0.22441\ttest-error:0.23421\n",
      "[163]\ttrain-error:0.22426\ttest-error:0.23418\n",
      "[164]\ttrain-error:0.22422\ttest-error:0.23397\n",
      "[165]\ttrain-error:0.22406\ttest-error:0.23413\n",
      "[166]\ttrain-error:0.22393\ttest-error:0.23388\n",
      "[167]\ttrain-error:0.22402\ttest-error:0.23386\n",
      "[168]\ttrain-error:0.22376\ttest-error:0.23372\n",
      "[169]\ttrain-error:0.22373\ttest-error:0.23361\n",
      "[170]\ttrain-error:0.22374\ttest-error:0.23370\n",
      "[171]\ttrain-error:0.22361\ttest-error:0.23370\n",
      "[172]\ttrain-error:0.22357\ttest-error:0.23360\n",
      "[173]\ttrain-error:0.22357\ttest-error:0.23353\n",
      "[174]\ttrain-error:0.22339\ttest-error:0.23356\n",
      "[175]\ttrain-error:0.22334\ttest-error:0.23356\n",
      "[176]\ttrain-error:0.22336\ttest-error:0.23353\n",
      "[177]\ttrain-error:0.22326\ttest-error:0.23335\n",
      "[178]\ttrain-error:0.22330\ttest-error:0.23315\n",
      "[179]\ttrain-error:0.22323\ttest-error:0.23317\n",
      "[180]\ttrain-error:0.22313\ttest-error:0.23303\n",
      "[181]\ttrain-error:0.22301\ttest-error:0.23298\n",
      "[182]\ttrain-error:0.22287\ttest-error:0.23284\n",
      "[183]\ttrain-error:0.22274\ttest-error:0.23305\n",
      "[184]\ttrain-error:0.22266\ttest-error:0.23305\n",
      "[185]\ttrain-error:0.22260\ttest-error:0.23301\n",
      "[186]\ttrain-error:0.22241\ttest-error:0.23317\n",
      "[187]\ttrain-error:0.22218\ttest-error:0.23278\n",
      "[188]\ttrain-error:0.22211\ttest-error:0.23277\n",
      "[189]\ttrain-error:0.22205\ttest-error:0.23262\n",
      "[190]\ttrain-error:0.22194\ttest-error:0.23270\n",
      "[191]\ttrain-error:0.22179\ttest-error:0.23264\n",
      "[192]\ttrain-error:0.22170\ttest-error:0.23266\n",
      "[193]\ttrain-error:0.22167\ttest-error:0.23255\n",
      "[194]\ttrain-error:0.22151\ttest-error:0.23247\n",
      "[195]\ttrain-error:0.22148\ttest-error:0.23245\n",
      "[196]\ttrain-error:0.22131\ttest-error:0.23250\n",
      "[197]\ttrain-error:0.22123\ttest-error:0.23248\n",
      "[198]\ttrain-error:0.22113\ttest-error:0.23247\n",
      "[199]\ttrain-error:0.22107\ttest-error:0.23232\n",
      "[200]\ttrain-error:0.22110\ttest-error:0.23227\n",
      "[201]\ttrain-error:0.22104\ttest-error:0.23227\n",
      "[202]\ttrain-error:0.22101\ttest-error:0.23215\n",
      "[203]\ttrain-error:0.22087\ttest-error:0.23236\n",
      "[204]\ttrain-error:0.22065\ttest-error:0.23243\n",
      "[205]\ttrain-error:0.22062\ttest-error:0.23236\n",
      "[206]\ttrain-error:0.22060\ttest-error:0.23232\n",
      "[207]\ttrain-error:0.22052\ttest-error:0.23218\n",
      "[208]\ttrain-error:0.22036\ttest-error:0.23215\n",
      "[209]\ttrain-error:0.22020\ttest-error:0.23217\n",
      "[210]\ttrain-error:0.21997\ttest-error:0.23204\n",
      "[211]\ttrain-error:0.22000\ttest-error:0.23194\n",
      "[212]\ttrain-error:0.21993\ttest-error:0.23202\n",
      "[213]\ttrain-error:0.21988\ttest-error:0.23217\n",
      "[214]\ttrain-error:0.21970\ttest-error:0.23190\n",
      "[215]\ttrain-error:0.21965\ttest-error:0.23185\n",
      "[216]\ttrain-error:0.21957\ttest-error:0.23174\n",
      "[217]\ttrain-error:0.21957\ttest-error:0.23176\n",
      "[218]\ttrain-error:0.21953\ttest-error:0.23176\n",
      "[219]\ttrain-error:0.21962\ttest-error:0.23160\n",
      "[220]\ttrain-error:0.21944\ttest-error:0.23169\n",
      "[221]\ttrain-error:0.21932\ttest-error:0.23156\n",
      "[222]\ttrain-error:0.21935\ttest-error:0.23162\n",
      "[223]\ttrain-error:0.21926\ttest-error:0.23162\n",
      "[224]\ttrain-error:0.21922\ttest-error:0.23164\n",
      "[225]\ttrain-error:0.21918\ttest-error:0.23171\n",
      "[226]\ttrain-error:0.21904\ttest-error:0.23151\n",
      "[227]\ttrain-error:0.21904\ttest-error:0.23155\n",
      "[228]\ttrain-error:0.21899\ttest-error:0.23156\n",
      "[229]\ttrain-error:0.21888\ttest-error:0.23162\n",
      "[230]\ttrain-error:0.21879\ttest-error:0.23149\n",
      "[231]\ttrain-error:0.21876\ttest-error:0.23149\n",
      "[232]\ttrain-error:0.21877\ttest-error:0.23151\n",
      "[233]\ttrain-error:0.21863\ttest-error:0.23144\n",
      "[234]\ttrain-error:0.21843\ttest-error:0.23132\n",
      "[235]\ttrain-error:0.21843\ttest-error:0.23132\n",
      "[236]\ttrain-error:0.21839\ttest-error:0.23125\n",
      "[237]\ttrain-error:0.21823\ttest-error:0.23139\n",
      "[238]\ttrain-error:0.21821\ttest-error:0.23132\n",
      "[239]\ttrain-error:0.21812\ttest-error:0.23128\n",
      "[240]\ttrain-error:0.21813\ttest-error:0.23137\n",
      "[241]\ttrain-error:0.21816\ttest-error:0.23134\n",
      "[242]\ttrain-error:0.21797\ttest-error:0.23144\n",
      "[243]\ttrain-error:0.21790\ttest-error:0.23144\n",
      "[244]\ttrain-error:0.21781\ttest-error:0.23135\n",
      "[245]\ttrain-error:0.21777\ttest-error:0.23121\n",
      "[246]\ttrain-error:0.21777\ttest-error:0.23125\n",
      "[247]\ttrain-error:0.21763\ttest-error:0.23125\n",
      "[248]\ttrain-error:0.21740\ttest-error:0.23121\n",
      "[249]\ttrain-error:0.21737\ttest-error:0.23126\n",
      "[250]\ttrain-error:0.21737\ttest-error:0.23132\n",
      "[251]\ttrain-error:0.21730\ttest-error:0.23112\n",
      "[252]\ttrain-error:0.21718\ttest-error:0.23107\n",
      "[253]\ttrain-error:0.21710\ttest-error:0.23105\n",
      "[254]\ttrain-error:0.21698\ttest-error:0.23100\n",
      "[255]\ttrain-error:0.21706\ttest-error:0.23105\n",
      "[256]\ttrain-error:0.21684\ttest-error:0.23102\n",
      "[257]\ttrain-error:0.21666\ttest-error:0.23098\n",
      "[258]\ttrain-error:0.21657\ttest-error:0.23095\n",
      "[259]\ttrain-error:0.21644\ttest-error:0.23095\n",
      "[260]\ttrain-error:0.21644\ttest-error:0.23093\n",
      "[261]\ttrain-error:0.21640\ttest-error:0.23089\n",
      "[262]\ttrain-error:0.21635\ttest-error:0.23087\n",
      "[263]\ttrain-error:0.21628\ttest-error:0.23082\n",
      "[264]\ttrain-error:0.21626\ttest-error:0.23091\n",
      "[265]\ttrain-error:0.21629\ttest-error:0.23056\n",
      "[266]\ttrain-error:0.21617\ttest-error:0.23042\n",
      "[267]\ttrain-error:0.21608\ttest-error:0.23042\n",
      "[268]\ttrain-error:0.21604\ttest-error:0.23038\n",
      "[269]\ttrain-error:0.21601\ttest-error:0.23040\n",
      "[270]\ttrain-error:0.21595\ttest-error:0.23045\n",
      "[271]\ttrain-error:0.21590\ttest-error:0.23047\n",
      "[272]\ttrain-error:0.21576\ttest-error:0.23042\n",
      "[273]\ttrain-error:0.21558\ttest-error:0.23031\n",
      "[274]\ttrain-error:0.21538\ttest-error:0.23042\n",
      "[275]\ttrain-error:0.21539\ttest-error:0.23038\n",
      "[276]\ttrain-error:0.21538\ttest-error:0.23031\n",
      "[277]\ttrain-error:0.21524\ttest-error:0.23022\n",
      "[278]\ttrain-error:0.21513\ttest-error:0.23019\n",
      "[279]\ttrain-error:0.21495\ttest-error:0.23033\n",
      "[280]\ttrain-error:0.21484\ttest-error:0.23029\n",
      "[281]\ttrain-error:0.21466\ttest-error:0.23022\n",
      "[282]\ttrain-error:0.21464\ttest-error:0.23015\n",
      "[283]\ttrain-error:0.21457\ttest-error:0.23010\n",
      "[284]\ttrain-error:0.21457\ttest-error:0.23015\n",
      "[285]\ttrain-error:0.21456\ttest-error:0.22999\n",
      "[286]\ttrain-error:0.21456\ttest-error:0.23001\n",
      "[287]\ttrain-error:0.21451\ttest-error:0.23001\n",
      "[288]\ttrain-error:0.21445\ttest-error:0.23004\n",
      "[289]\ttrain-error:0.21436\ttest-error:0.23006\n",
      "[290]\ttrain-error:0.21431\ttest-error:0.23006\n",
      "[291]\ttrain-error:0.21424\ttest-error:0.22987\n",
      "[292]\ttrain-error:0.21419\ttest-error:0.22969\n",
      "[293]\ttrain-error:0.21419\ttest-error:0.22973\n",
      "[294]\ttrain-error:0.21413\ttest-error:0.22973\n",
      "[295]\ttrain-error:0.21407\ttest-error:0.22967\n",
      "[296]\ttrain-error:0.21407\ttest-error:0.22962\n",
      "[297]\ttrain-error:0.21394\ttest-error:0.22953\n",
      "[298]\ttrain-error:0.21393\ttest-error:0.22969\n",
      "[299]\ttrain-error:0.21382\ttest-error:0.22983\n",
      "[300]\ttrain-error:0.21367\ttest-error:0.22996\n",
      "[301]\ttrain-error:0.21360\ttest-error:0.22983\n",
      "[302]\ttrain-error:0.21355\ttest-error:0.22978\n",
      "[303]\ttrain-error:0.21353\ttest-error:0.22978\n",
      "[304]\ttrain-error:0.21329\ttest-error:0.22976\n",
      "[305]\ttrain-error:0.21327\ttest-error:0.22962\n",
      "[306]\ttrain-error:0.21309\ttest-error:0.22964\n",
      "[307]\ttrain-error:0.21315\ttest-error:0.22960\n",
      "[308]\ttrain-error:0.21315\ttest-error:0.22955\n",
      "[309]\ttrain-error:0.21297\ttest-error:0.22967\n",
      "[310]\ttrain-error:0.21290\ttest-error:0.22959\n",
      "[311]\ttrain-error:0.21293\ttest-error:0.22943\n",
      "[312]\ttrain-error:0.21284\ttest-error:0.22953\n",
      "[313]\ttrain-error:0.21277\ttest-error:0.22950\n",
      "[314]\ttrain-error:0.21279\ttest-error:0.22960\n",
      "[315]\ttrain-error:0.21256\ttest-error:0.22962\n",
      "[316]\ttrain-error:0.21256\ttest-error:0.22955\n",
      "[317]\ttrain-error:0.21246\ttest-error:0.22946\n",
      "[318]\ttrain-error:0.21243\ttest-error:0.22946\n",
      "[319]\ttrain-error:0.21241\ttest-error:0.22943\n",
      "[320]\ttrain-error:0.21225\ttest-error:0.22941\n",
      "[321]\ttrain-error:0.21210\ttest-error:0.22934\n",
      "[322]\ttrain-error:0.21219\ttest-error:0.22925\n",
      "[323]\ttrain-error:0.21225\ttest-error:0.22932\n",
      "[324]\ttrain-error:0.21222\ttest-error:0.22928\n",
      "[325]\ttrain-error:0.21218\ttest-error:0.22927\n",
      "[326]\ttrain-error:0.21210\ttest-error:0.22920\n",
      "[327]\ttrain-error:0.21205\ttest-error:0.22923\n",
      "[328]\ttrain-error:0.21194\ttest-error:0.22934\n",
      "[329]\ttrain-error:0.21189\ttest-error:0.22923\n",
      "[330]\ttrain-error:0.21188\ttest-error:0.22934\n",
      "[331]\ttrain-error:0.21188\ttest-error:0.22927\n",
      "[332]\ttrain-error:0.21179\ttest-error:0.22916\n",
      "[333]\ttrain-error:0.21169\ttest-error:0.22909\n",
      "[334]\ttrain-error:0.21163\ttest-error:0.22907\n",
      "[335]\ttrain-error:0.21161\ttest-error:0.22906\n",
      "[336]\ttrain-error:0.21151\ttest-error:0.22906\n",
      "[337]\ttrain-error:0.21148\ttest-error:0.22900\n",
      "[338]\ttrain-error:0.21151\ttest-error:0.22904\n",
      "[339]\ttrain-error:0.21140\ttest-error:0.22906\n",
      "[340]\ttrain-error:0.21130\ttest-error:0.22904\n",
      "[341]\ttrain-error:0.21117\ttest-error:0.22911\n",
      "[342]\ttrain-error:0.21116\ttest-error:0.22907\n",
      "[343]\ttrain-error:0.21111\ttest-error:0.22914\n",
      "[344]\ttrain-error:0.21099\ttest-error:0.22907\n",
      "[345]\ttrain-error:0.21095\ttest-error:0.22907\n",
      "[346]\ttrain-error:0.21083\ttest-error:0.22911\n",
      "[347]\ttrain-error:0.21080\ttest-error:0.22916\n",
      "[348]\ttrain-error:0.21077\ttest-error:0.22907\n",
      "[349]\ttrain-error:0.21078\ttest-error:0.22911\n",
      "[350]\ttrain-error:0.21065\ttest-error:0.22891\n",
      "[351]\ttrain-error:0.21058\ttest-error:0.22888\n",
      "[352]\ttrain-error:0.21052\ttest-error:0.22879\n",
      "[353]\ttrain-error:0.21045\ttest-error:0.22886\n",
      "[354]\ttrain-error:0.21032\ttest-error:0.22886\n",
      "[355]\ttrain-error:0.21033\ttest-error:0.22879\n",
      "[356]\ttrain-error:0.21019\ttest-error:0.22847\n",
      "[357]\ttrain-error:0.21023\ttest-error:0.22854\n",
      "[358]\ttrain-error:0.21012\ttest-error:0.22847\n",
      "[359]\ttrain-error:0.21009\ttest-error:0.22865\n",
      "[360]\ttrain-error:0.21010\ttest-error:0.22849\n",
      "[361]\ttrain-error:0.21009\ttest-error:0.22853\n",
      "[362]\ttrain-error:0.21006\ttest-error:0.22868\n",
      "[363]\ttrain-error:0.20999\ttest-error:0.22875\n",
      "[364]\ttrain-error:0.20991\ttest-error:0.22868\n",
      "[365]\ttrain-error:0.20977\ttest-error:0.22845\n",
      "[366]\ttrain-error:0.20975\ttest-error:0.22847\n",
      "[367]\ttrain-error:0.20965\ttest-error:0.22844\n",
      "[368]\ttrain-error:0.20965\ttest-error:0.22844\n",
      "[369]\ttrain-error:0.20960\ttest-error:0.22838\n",
      "[370]\ttrain-error:0.20960\ttest-error:0.22845\n",
      "[371]\ttrain-error:0.20958\ttest-error:0.22853\n",
      "[372]\ttrain-error:0.20962\ttest-error:0.22849\n",
      "[373]\ttrain-error:0.20966\ttest-error:0.22853\n",
      "[374]\ttrain-error:0.20958\ttest-error:0.22849\n",
      "[375]\ttrain-error:0.20947\ttest-error:0.22863\n",
      "[376]\ttrain-error:0.20947\ttest-error:0.22858\n",
      "[377]\ttrain-error:0.20938\ttest-error:0.22860\n",
      "[378]\ttrain-error:0.20935\ttest-error:0.22868\n",
      "[379]\ttrain-error:0.20936\ttest-error:0.22853\n",
      "[380]\ttrain-error:0.20935\ttest-error:0.22844\n",
      "[381]\ttrain-error:0.20933\ttest-error:0.22838\n",
      "[382]\ttrain-error:0.20920\ttest-error:0.22831\n",
      "[383]\ttrain-error:0.20910\ttest-error:0.22842\n",
      "[384]\ttrain-error:0.20906\ttest-error:0.22833\n",
      "[385]\ttrain-error:0.20904\ttest-error:0.22831\n",
      "[386]\ttrain-error:0.20904\ttest-error:0.22844\n",
      "[387]\ttrain-error:0.20888\ttest-error:0.22853\n",
      "[388]\ttrain-error:0.20886\ttest-error:0.22847\n",
      "[389]\ttrain-error:0.20889\ttest-error:0.22842\n",
      "[390]\ttrain-error:0.20881\ttest-error:0.22840\n",
      "[391]\ttrain-error:0.20873\ttest-error:0.22826\n",
      "[392]\ttrain-error:0.20859\ttest-error:0.22835\n",
      "[393]\ttrain-error:0.20858\ttest-error:0.22830\n",
      "[394]\ttrain-error:0.20856\ttest-error:0.22828\n",
      "[395]\ttrain-error:0.20854\ttest-error:0.22835\n",
      "[396]\ttrain-error:0.20852\ttest-error:0.22831\n",
      "[397]\ttrain-error:0.20840\ttest-error:0.22824\n",
      "[398]\ttrain-error:0.20828\ttest-error:0.22830\n",
      "[399]\ttrain-error:0.20824\ttest-error:0.22821\n",
      "[400]\ttrain-error:0.20828\ttest-error:0.22823\n",
      "[401]\ttrain-error:0.20811\ttest-error:0.22814\n",
      "[402]\ttrain-error:0.20811\ttest-error:0.22812\n",
      "[403]\ttrain-error:0.20805\ttest-error:0.22810\n",
      "[404]\ttrain-error:0.20800\ttest-error:0.22805\n",
      "[405]\ttrain-error:0.20801\ttest-error:0.22792\n",
      "[406]\ttrain-error:0.20792\ttest-error:0.22796\n",
      "[407]\ttrain-error:0.20768\ttest-error:0.22801\n",
      "[408]\ttrain-error:0.20761\ttest-error:0.22791\n",
      "[409]\ttrain-error:0.20763\ttest-error:0.22807\n",
      "[410]\ttrain-error:0.20743\ttest-error:0.22803\n",
      "[411]\ttrain-error:0.20745\ttest-error:0.22808\n",
      "[412]\ttrain-error:0.20734\ttest-error:0.22798\n",
      "[413]\ttrain-error:0.20739\ttest-error:0.22805\n",
      "[414]\ttrain-error:0.20733\ttest-error:0.22808\n",
      "[415]\ttrain-error:0.20728\ttest-error:0.22805\n",
      "[416]\ttrain-error:0.20726\ttest-error:0.22800\n",
      "[417]\ttrain-error:0.20721\ttest-error:0.22787\n",
      "[418]\ttrain-error:0.20719\ttest-error:0.22801\n",
      "[419]\ttrain-error:0.20713\ttest-error:0.22810\n",
      "[420]\ttrain-error:0.20713\ttest-error:0.22808\n",
      "[421]\ttrain-error:0.20701\ttest-error:0.22808\n",
      "[422]\ttrain-error:0.20694\ttest-error:0.22805\n",
      "[423]\ttrain-error:0.20691\ttest-error:0.22812\n",
      "[424]\ttrain-error:0.20681\ttest-error:0.22814\n",
      "[425]\ttrain-error:0.20678\ttest-error:0.22801\n",
      "[426]\ttrain-error:0.20681\ttest-error:0.22792\n",
      "[427]\ttrain-error:0.20682\ttest-error:0.22789\n",
      "[428]\ttrain-error:0.20675\ttest-error:0.22789\n",
      "[429]\ttrain-error:0.20675\ttest-error:0.22791\n",
      "[430]\ttrain-error:0.20663\ttest-error:0.22798\n",
      "[431]\ttrain-error:0.20655\ttest-error:0.22785\n",
      "[432]\ttrain-error:0.20634\ttest-error:0.22782\n",
      "[433]\ttrain-error:0.20640\ttest-error:0.22789\n",
      "[434]\ttrain-error:0.20639\ttest-error:0.22784\n",
      "[435]\ttrain-error:0.20629\ttest-error:0.22777\n",
      "[436]\ttrain-error:0.20605\ttest-error:0.22773\n",
      "[437]\ttrain-error:0.20597\ttest-error:0.22784\n",
      "[438]\ttrain-error:0.20600\ttest-error:0.22787\n",
      "[439]\ttrain-error:0.20591\ttest-error:0.22787\n",
      "[440]\ttrain-error:0.20589\ttest-error:0.22784\n",
      "[441]\ttrain-error:0.20580\ttest-error:0.22785\n",
      "[442]\ttrain-error:0.20570\ttest-error:0.22787\n",
      "[443]\ttrain-error:0.20564\ttest-error:0.22789\n",
      "[444]\ttrain-error:0.20557\ttest-error:0.22784\n",
      "[445]\ttrain-error:0.20555\ttest-error:0.22773\n",
      "[446]\ttrain-error:0.20550\ttest-error:0.22773\n",
      "[447]\ttrain-error:0.20547\ttest-error:0.22777\n",
      "[448]\ttrain-error:0.20546\ttest-error:0.22775\n",
      "[449]\ttrain-error:0.20538\ttest-error:0.22784\n",
      "[450]\ttrain-error:0.20526\ttest-error:0.22768\n",
      "[451]\ttrain-error:0.20514\ttest-error:0.22771\n",
      "[452]\ttrain-error:0.20503\ttest-error:0.22761\n",
      "[453]\ttrain-error:0.20497\ttest-error:0.22771\n",
      "[454]\ttrain-error:0.20498\ttest-error:0.22771\n",
      "[455]\ttrain-error:0.20491\ttest-error:0.22764\n",
      "[456]\ttrain-error:0.20493\ttest-error:0.22755\n",
      "[457]\ttrain-error:0.20475\ttest-error:0.22757\n",
      "[458]\ttrain-error:0.20478\ttest-error:0.22759\n",
      "[459]\ttrain-error:0.20479\ttest-error:0.22750\n",
      "[460]\ttrain-error:0.20472\ttest-error:0.22762\n",
      "[461]\ttrain-error:0.20464\ttest-error:0.22759\n",
      "[462]\ttrain-error:0.20459\ttest-error:0.22752\n",
      "[463]\ttrain-error:0.20450\ttest-error:0.22754\n",
      "[464]\ttrain-error:0.20452\ttest-error:0.22748\n",
      "[465]\ttrain-error:0.20447\ttest-error:0.22747\n",
      "[466]\ttrain-error:0.20437\ttest-error:0.22740\n",
      "[467]\ttrain-error:0.20441\ttest-error:0.22734\n",
      "[468]\ttrain-error:0.20428\ttest-error:0.22752\n",
      "[469]\ttrain-error:0.20433\ttest-error:0.22747\n",
      "[470]\ttrain-error:0.20439\ttest-error:0.22740\n",
      "[471]\ttrain-error:0.20428\ttest-error:0.22738\n",
      "[472]\ttrain-error:0.20417\ttest-error:0.22738\n",
      "[473]\ttrain-error:0.20420\ttest-error:0.22743\n",
      "[474]\ttrain-error:0.20407\ttest-error:0.22757\n",
      "[475]\ttrain-error:0.20406\ttest-error:0.22752\n",
      "[476]\ttrain-error:0.20392\ttest-error:0.22740\n",
      "[477]\ttrain-error:0.20388\ttest-error:0.22741\n",
      "[478]\ttrain-error:0.20382\ttest-error:0.22747\n",
      "[479]\ttrain-error:0.20377\ttest-error:0.22748\n",
      "[480]\ttrain-error:0.20372\ttest-error:0.22725\n",
      "[481]\ttrain-error:0.20362\ttest-error:0.22727\n",
      "[482]\ttrain-error:0.20357\ttest-error:0.22715\n",
      "[483]\ttrain-error:0.20340\ttest-error:0.22709\n",
      "[484]\ttrain-error:0.20335\ttest-error:0.22725\n",
      "[485]\ttrain-error:0.20332\ttest-error:0.22729\n",
      "[486]\ttrain-error:0.20333\ttest-error:0.22731\n",
      "[487]\ttrain-error:0.20329\ttest-error:0.22731\n",
      "[488]\ttrain-error:0.20324\ttest-error:0.22732\n",
      "[489]\ttrain-error:0.20325\ttest-error:0.22715\n",
      "[490]\ttrain-error:0.20320\ttest-error:0.22718\n",
      "[491]\ttrain-error:0.20317\ttest-error:0.22720\n",
      "[492]\ttrain-error:0.20308\ttest-error:0.22711\n",
      "[493]\ttrain-error:0.20299\ttest-error:0.22713\n",
      "[494]\ttrain-error:0.20293\ttest-error:0.22717\n",
      "[495]\ttrain-error:0.20285\ttest-error:0.22697\n",
      "[496]\ttrain-error:0.20284\ttest-error:0.22702\n",
      "[497]\ttrain-error:0.20283\ttest-error:0.22704\n",
      "[498]\ttrain-error:0.20281\ttest-error:0.22709\n",
      "[499]\ttrain-error:0.20269\ttest-error:0.22729\n"
     ]
    }
   ],
   "source": [
    "dtrain, dtest = xgb.DMatrix(X_train,y_train, feature_names=FEATS), xgb.DMatrix(X_test,y_test, feature_names=FEATS)\n",
    "\n",
    "ROUNDS = 500\n",
    "EVAL_LIST = [(dtrain, \"train\"),(dtest, \"test\")]\n",
    "\n",
    "xgb_model = xgb.train(params,dtrain,ROUNDS,EVAL_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_P</th>\n",
       "      <td>170.013235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT_METHOD_NonDD</th>\n",
       "      <td>47.193247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOME_EM_ADDON_POST_REN_Y</th>\n",
       "      <td>26.109552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD_BUILDINGS_Y</th>\n",
       "      <td>24.743001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KEYCARE_ADDON_PRE_REN_Y</th>\n",
       "      <td>22.145358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX_DAYS_UNOCC</th>\n",
       "      <td>21.692534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP1_ADDON_POST_REN_Y</th>\n",
       "      <td>20.775646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP2_ADDON_POST_REN_Y</th>\n",
       "      <td>20.063199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEGAL_ADDON_POST_REN_Y</th>\n",
       "      <td>18.202539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT_METHOD_PureDD</th>\n",
       "      <td>17.556776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP3_ADDON_POST_REN_Y</th>\n",
       "      <td>15.941809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUM_INSURED_BUILDINGS</th>\n",
       "      <td>15.675539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARDEN_ADDON_PRE_REN_Y</th>\n",
       "      <td>14.565703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KEYCARE_ADDON_POST_REN_Y</th>\n",
       "      <td>13.675880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCC_STATUS_LP</th>\n",
       "      <td>12.632733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARDEN_ADDON_POST_REN_Y</th>\n",
       "      <td>12.277981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOME_EM_ADDON_PRE_REN_Y</th>\n",
       "      <td>11.742306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTA_FLAG_Y</th>\n",
       "      <td>10.789477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_2.0</th>\n",
       "      <td>9.435106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_O</th>\n",
       "      <td>9.230607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_22.0</th>\n",
       "      <td>8.713453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCD_GRANTED_YEARS_B</th>\n",
       "      <td>8.266899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUBSIDENCE_Y</th>\n",
       "      <td>8.204736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cover_length</th>\n",
       "      <td>8.037479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCC_STATUS_PH</th>\n",
       "      <td>7.679981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_2.0</th>\n",
       "      <td>7.634772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_51.0</th>\n",
       "      <td>7.634436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUM_INSURED_CONTENTS</th>\n",
       "      <td>7.485276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUILDINGS_COVER_Y</th>\n",
       "      <td>7.424712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_RATED_AREA_C_imputed</th>\n",
       "      <td>7.068925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RISK_RATED_AREA_B_imputed</th>\n",
       "      <td>6.689967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCD_GRANTED_YEARS_C</th>\n",
       "      <td>6.622818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAFE_INSTALLED_Y</th>\n",
       "      <td>6.621982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTA_FAP_imputed</th>\n",
       "      <td>6.340095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_16.0</th>\n",
       "      <td>6.281836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNSPEC_HRP_PREM</th>\n",
       "      <td>6.224119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_4.0</th>\n",
       "      <td>6.172431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCC_STATUS_UN</th>\n",
       "      <td>6.160243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_H</th>\n",
       "      <td>6.137361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOODING_Y</th>\n",
       "      <td>6.006965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_17.0</th>\n",
       "      <td>5.977949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAST_ANN_PREM_GROSS</th>\n",
       "      <td>5.877564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPEC_ITEM_PREM</th>\n",
       "      <td>5.775829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUS_USE_Y</th>\n",
       "      <td>5.761504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_18.0</th>\n",
       "      <td>5.718065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_D</th>\n",
       "      <td>5.690293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_32.0</th>\n",
       "      <td>5.669324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTA_APRP_imputed</th>\n",
       "      <td>5.602118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP2_ADDON_PRE_REN_Y</th>\n",
       "      <td>5.572457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPEC_SUM_INSURED</th>\n",
       "      <td>5.565167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_7.0</th>\n",
       "      <td>5.493985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLAIM3YEARS_Y</th>\n",
       "      <td>5.458455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_45.0</th>\n",
       "      <td>5.301980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_53.0</th>\n",
       "      <td>5.259304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_U</th>\n",
       "      <td>5.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_M</th>\n",
       "      <td>5.104878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_S</th>\n",
       "      <td>5.098258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_age</th>\n",
       "      <td>5.092778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_W</th>\n",
       "      <td>5.069282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_26.0</th>\n",
       "      <td>5.013073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_7.0</th>\n",
       "      <td>4.978121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_S</th>\n",
       "      <td>4.906850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_N</th>\n",
       "      <td>4.894169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_9.0</th>\n",
       "      <td>4.877387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_52.0</th>\n",
       "      <td>4.829099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>4.823992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_MAR_STATUS_C</th>\n",
       "      <td>4.771094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_14.0</th>\n",
       "      <td>4.759505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEDROOMS</th>\n",
       "      <td>4.733171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_25.0</th>\n",
       "      <td>4.654037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_19.0</th>\n",
       "      <td>4.643327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_18.0</th>\n",
       "      <td>4.640873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_E</th>\n",
       "      <td>4.625132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APPR_ALARM_Y</th>\n",
       "      <td>4.612885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_12.0</th>\n",
       "      <td>4.402632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_3.0</th>\n",
       "      <td>4.378780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_48.0</th>\n",
       "      <td>4.291513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APPR_LOCKS_Y</th>\n",
       "      <td>4.126195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_EMP_STATUS_R</th>\n",
       "      <td>4.076524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEC_DISC_REQ_Y</th>\n",
       "      <td>4.060985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_13.0</th>\n",
       "      <td>4.024259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNERSHIP_TYPE_8.0</th>\n",
       "      <td>4.006247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1_SEX_M</th>\n",
       "      <td>3.958018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_10.0</th>\n",
       "      <td>3.947126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROP_TYPE_47.0</th>\n",
       "      <td>3.913844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEIGH_WATCH_Y</th>\n",
       "      <td>3.880506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "P1_MAR_STATUS_P            170.013235\n",
       "PAYMENT_METHOD_NonDD        47.193247\n",
       "HOME_EM_ADDON_POST_REN_Y    26.109552\n",
       "AD_BUILDINGS_Y              24.743001\n",
       "KEYCARE_ADDON_PRE_REN_Y     22.145358\n",
       "MAX_DAYS_UNOCC              21.692534\n",
       "HP1_ADDON_POST_REN_Y        20.775646\n",
       "HP2_ADDON_POST_REN_Y        20.063199\n",
       "LEGAL_ADDON_POST_REN_Y      18.202539\n",
       "PAYMENT_METHOD_PureDD       17.556776\n",
       "HP3_ADDON_POST_REN_Y        15.941809\n",
       "SUM_INSURED_BUILDINGS       15.675539\n",
       "GARDEN_ADDON_PRE_REN_Y      14.565703\n",
       "KEYCARE_ADDON_POST_REN_Y    13.675880\n",
       "OCC_STATUS_LP               12.632733\n",
       "GARDEN_ADDON_POST_REN_Y     12.277981\n",
       "HOME_EM_ADDON_PRE_REN_Y     11.742306\n",
       "MTA_FLAG_Y                  10.789477\n",
       "PROP_TYPE_2.0                9.435106\n",
       "P1_MAR_STATUS_O              9.230607\n",
       "PROP_TYPE_22.0               8.713453\n",
       "NCD_GRANTED_YEARS_B          8.266899\n",
       "SUBSIDENCE_Y                 8.204736\n",
       "cover_length                 8.037479\n",
       "OCC_STATUS_PH                7.679981\n",
       "OWNERSHIP_TYPE_2.0           7.634772\n",
       "PROP_TYPE_51.0               7.634436\n",
       "SUM_INSURED_CONTENTS         7.485276\n",
       "BUILDINGS_COVER_Y            7.424712\n",
       "RISK_RATED_AREA_C_imputed    7.068925\n",
       "RISK_RATED_AREA_B_imputed    6.689967\n",
       "NCD_GRANTED_YEARS_C          6.622818\n",
       "SAFE_INSTALLED_Y             6.621982\n",
       "MTA_FAP_imputed              6.340095\n",
       "PROP_TYPE_16.0               6.281836\n",
       "UNSPEC_HRP_PREM              6.224119\n",
       "PROP_TYPE_4.0                6.172431\n",
       "OCC_STATUS_UN                6.160243\n",
       "P1_EMP_STATUS_H              6.137361\n",
       "FLOODING_Y                   6.006965\n",
       "PROP_TYPE_17.0               5.977949\n",
       "LAST_ANN_PREM_GROSS          5.877564\n",
       "SPEC_ITEM_PREM               5.775829\n",
       "BUS_USE_Y                    5.761504\n",
       "PROP_TYPE_18.0               5.718065\n",
       "P1_MAR_STATUS_D              5.690293\n",
       "PROP_TYPE_32.0               5.669324\n",
       "MTA_APRP_imputed             5.602118\n",
       "HP2_ADDON_PRE_REN_Y          5.572457\n",
       "SPEC_SUM_INSURED             5.565167\n",
       "OWNERSHIP_TYPE_7.0           5.493985\n",
       "CLAIM3YEARS_Y                5.458455\n",
       "PROP_TYPE_45.0               5.301980\n",
       "PROP_TYPE_53.0               5.259304\n",
       "P1_EMP_STATUS_U              5.259000\n",
       "P1_MAR_STATUS_M              5.104878\n",
       "P1_EMP_STATUS_S              5.098258\n",
       "property_age                 5.092778\n",
       "P1_MAR_STATUS_W              5.069282\n",
       "PROP_TYPE_26.0               5.013073\n",
       "PROP_TYPE_7.0                4.978121\n",
       "P1_MAR_STATUS_S              4.906850\n",
       "P1_EMP_STATUS_N              4.894169\n",
       "PROP_TYPE_9.0                4.877387\n",
       "PROP_TYPE_52.0               4.829099\n",
       "age                          4.823992\n",
       "P1_MAR_STATUS_C              4.771094\n",
       "OWNERSHIP_TYPE_14.0          4.759505\n",
       "BEDROOMS                     4.733171\n",
       "PROP_TYPE_25.0               4.654037\n",
       "PROP_TYPE_19.0               4.643327\n",
       "OWNERSHIP_TYPE_18.0          4.640873\n",
       "P1_EMP_STATUS_E              4.625132\n",
       "APPR_ALARM_Y                 4.612885\n",
       "OWNERSHIP_TYPE_12.0          4.402632\n",
       "OWNERSHIP_TYPE_3.0           4.378780\n",
       "PROP_TYPE_48.0               4.291513\n",
       "APPR_LOCKS_Y                 4.126195\n",
       "P1_EMP_STATUS_R              4.076524\n",
       "SEC_DISC_REQ_Y               4.060985\n",
       "OWNERSHIP_TYPE_13.0          4.024259\n",
       "OWNERSHIP_TYPE_8.0           4.006247\n",
       "P1_SEX_M                     3.958018\n",
       "PROP_TYPE_10.0               3.947126\n",
       "PROP_TYPE_47.0               3.913844\n",
       "NEIGH_WATCH_Y                3.880506"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain = pd.DataFrame.from_dict(xgb_model.get_score(importance_type=\"gain\"),orient=\"index\").sort_values(0,ascending=False)\n",
    "gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapley values for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bytearray = xgb_model.save_raw()[4:]\n",
    "\n",
    "def bytearrayTransform(self=None):\n",
    "    return model_bytearray\n",
    "\n",
    "xgb_model.save_raw = bytearrayTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x684 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_values = shap.TreeExplainer(xgb_model).shap_values(X_train)\n",
    "\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.save_model(\"resources/models/xgb_model-2021-02-14.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = xgb_model.predict(dtrain)\n",
    "prediction = xgb_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for training set is 0.7452\n",
      "Accuracy score for test set is 0.7013\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for training set is \" + str(round(accuracy_score(y_train, \n",
    "                                                           np.where(prediction_train > .2776,\n",
    "                                                                    1, 0)),4)))\n",
    "print(\"Accuracy score for test set is \" + str(round(accuracy_score(y_test, np.where(prediction > .2776,\n",
    "                                                                        1, 0)),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set is 0.6233\n",
      "F1 score for test set is 0.5606\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score for training set is \" + str(round(f1_score(y_train, \n",
    "                                                           np.where(prediction_train > .2776,\n",
    "                                                                    1, 0)),4)))\n",
    "print(\"F1 score for test set is \" + str(round(f1_score(y_test, np.where(prediction > .2776,\n",
    "                                                                        1, 0)),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset is 256136\n",
      "The size of the training set is 132403\n",
      "The size of the test set is 56602\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of the dataset is \" +\n",
    "      str(len(df))\n",
    "     )\n",
    "print(\"The size of the training set is \" +\n",
    "      str(len(y_train))\n",
    "     )\n",
    "print(\"The size of the test set is \" +\n",
    "      str(len(y_test))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28907, 11972],\n",
       "       [ 4936, 10787]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, np.where(prediction > .2776, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D-CNN model\n",
    "This architecture is known with supreme predictive power. I was expecting with this model, it will improve the model performance but it was slightly worse than XGBoost model. Also due to time constrain, I didn't have time to fine-tune the model so it might be also the reason. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 38s 2s/step - loss: 0.6048 - binary_crossentropy: 0.6048 - val_loss: 0.6646 - val_binary_crossentropy: 0.6646\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 20s 910ms/step - loss: 0.5295 - binary_crossentropy: 0.5295 - val_loss: 0.6572 - val_binary_crossentropy: 0.6572\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 20s 906ms/step - loss: 0.5223 - binary_crossentropy: 0.5223 - val_loss: 0.6510 - val_binary_crossentropy: 0.6510\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 20s 890ms/step - loss: 0.5166 - binary_crossentropy: 0.5166 - val_loss: 0.6413 - val_binary_crossentropy: 0.6413\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 21s 956ms/step - loss: 0.5114 - binary_crossentropy: 0.5114 - val_loss: 0.6351 - val_binary_crossentropy: 0.6351\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 20s 905ms/step - loss: 0.5071 - binary_crossentropy: 0.5071 - val_loss: 0.6286 - val_binary_crossentropy: 0.6286\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 22s 983ms/step - loss: 0.5022 - binary_crossentropy: 0.5022 - val_loss: 0.6110 - val_binary_crossentropy: 0.6110\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 21s 940ms/step - loss: 0.5008 - binary_crossentropy: 0.5008 - val_loss: 0.6071 - val_binary_crossentropy: 0.6071\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 19s 866ms/step - loss: 0.4974 - binary_crossentropy: 0.4974 - val_loss: 0.5859 - val_binary_crossentropy: 0.5859\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 20s 892ms/step - loss: 0.4942 - binary_crossentropy: 0.4942 - val_loss: 0.5726 - val_binary_crossentropy: 0.5726\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 20s 888ms/step - loss: 0.4915 - binary_crossentropy: 0.4915 - val_loss: 0.5758 - val_binary_crossentropy: 0.5758\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 19s 886ms/step - loss: 0.4851 - binary_crossentropy: 0.4851 - val_loss: 0.5644 - val_binary_crossentropy: 0.5644\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 19s 871ms/step - loss: 0.4861 - binary_crossentropy: 0.4861 - val_loss: 0.5549 - val_binary_crossentropy: 0.5549\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 21s 945ms/step - loss: 0.4822 - binary_crossentropy: 0.4822 - val_loss: 0.5324 - val_binary_crossentropy: 0.5324\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 20s 916ms/step - loss: 0.4815 - binary_crossentropy: 0.4815 - val_loss: 0.5345 - val_binary_crossentropy: 0.5345\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.4758 - binary_crossentropy: 0.4758 - val_loss: 0.5281 - val_binary_crossentropy: 0.5281\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 20s 923ms/step - loss: 0.4691 - binary_crossentropy: 0.4691 - val_loss: 0.5317 - val_binary_crossentropy: 0.5317\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 19s 845ms/step - loss: 0.4720 - binary_crossentropy: 0.4720 - val_loss: 0.5145 - val_binary_crossentropy: 0.5145\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 19s 863ms/step - loss: 0.4687 - binary_crossentropy: 0.4687 - val_loss: 0.5279 - val_binary_crossentropy: 0.5279\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 17s 782ms/step - loss: 0.4678 - binary_crossentropy: 0.4678 - val_loss: 0.5209 - val_binary_crossentropy: 0.5209\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 21s 947ms/step - loss: 0.4644 - binary_crossentropy: 0.4644 - val_loss: 0.5209 - val_binary_crossentropy: 0.5209\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 19s 847ms/step - loss: 0.4611 - binary_crossentropy: 0.4611 - val_loss: 0.5191 - val_binary_crossentropy: 0.5191\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 20s 896ms/step - loss: 0.4582 - binary_crossentropy: 0.4582 - val_loss: 0.5227 - val_binary_crossentropy: 0.5227\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 32s 1s/step - loss: 0.6197 - binary_crossentropy: 0.6197 - val_loss: 0.6704 - val_binary_crossentropy: 0.6704\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 18s 795ms/step - loss: 0.5362 - binary_crossentropy: 0.5362 - val_loss: 0.6626 - val_binary_crossentropy: 0.6626\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 22s 1s/step - loss: 0.5230 - binary_crossentropy: 0.5230 - val_loss: 0.6543 - val_binary_crossentropy: 0.6543\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.5180 - binary_crossentropy: 0.5180 - val_loss: 0.6471 - val_binary_crossentropy: 0.6471\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.5133 - binary_crossentropy: 0.5133 - val_loss: 0.6378 - val_binary_crossentropy: 0.6378\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 22s 979ms/step - loss: 0.5103 - binary_crossentropy: 0.5103 - val_loss: 0.6266 - val_binary_crossentropy: 0.6266\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 21s 943ms/step - loss: 0.5068 - binary_crossentropy: 0.5068 - val_loss: 0.6174 - val_binary_crossentropy: 0.6174\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 20s 901ms/step - loss: 0.5042 - binary_crossentropy: 0.5042 - val_loss: 0.6066 - val_binary_crossentropy: 0.6066\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 21s 936ms/step - loss: 0.5023 - binary_crossentropy: 0.5023 - val_loss: 0.5962 - val_binary_crossentropy: 0.5962\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 20s 902ms/step - loss: 0.4994 - binary_crossentropy: 0.4994 - val_loss: 0.5786 - val_binary_crossentropy: 0.5786\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 20s 917ms/step - loss: 0.4994 - binary_crossentropy: 0.4994 - val_loss: 0.5765 - val_binary_crossentropy: 0.5765\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 21s 960ms/step - loss: 0.4939 - binary_crossentropy: 0.4939 - val_loss: 0.5647 - val_binary_crossentropy: 0.5647\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 19s 844ms/step - loss: 0.4922 - binary_crossentropy: 0.4922 - val_loss: 0.5466 - val_binary_crossentropy: 0.5466\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 22s 1000ms/step - loss: 0.4906 - binary_crossentropy: 0.4906 - val_loss: 0.5438 - val_binary_crossentropy: 0.5438\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 19s 867ms/step - loss: 0.4890 - binary_crossentropy: 0.4890 - val_loss: 0.5382 - val_binary_crossentropy: 0.5382\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 19s 863ms/step - loss: 0.4856 - binary_crossentropy: 0.4856 - val_loss: 0.5332 - val_binary_crossentropy: 0.5332\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.4842 - binary_crossentropy: 0.4842 - val_loss: 0.5372 - val_binary_crossentropy: 0.5372\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 18s 836ms/step - loss: 0.4808 - binary_crossentropy: 0.4808 - val_loss: 0.5358 - val_binary_crossentropy: 0.5358\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 38s 2s/step - loss: 0.4779 - binary_crossentropy: 0.4779 - val_loss: 0.5299 - val_binary_crossentropy: 0.5299\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 27s 1s/step - loss: 0.4752 - binary_crossentropy: 0.4752 - val_loss: 0.5305 - val_binary_crossentropy: 0.5305\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.4724 - binary_crossentropy: 0.4724 - val_loss: 0.5360 - val_binary_crossentropy: 0.5360\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 20s 903ms/step - loss: 0.4738 - binary_crossentropy: 0.4738 - val_loss: 0.5293 - val_binary_crossentropy: 0.5293\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 19s 868ms/step - loss: 0.4689 - binary_crossentropy: 0.4689 - val_loss: 0.5368 - val_binary_crossentropy: 0.5368\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 18s 803ms/step - loss: 0.4642 - binary_crossentropy: 0.4642 - val_loss: 0.5361 - val_binary_crossentropy: 0.5361\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 30s 1s/step - loss: 0.6409 - binary_crossentropy: 0.6409 - val_loss: 0.6624 - val_binary_crossentropy: 0.6624\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 17s 790ms/step - loss: 0.5340 - binary_crossentropy: 0.5340 - val_loss: 0.6560 - val_binary_crossentropy: 0.6560\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 17s 792ms/step - loss: 0.5213 - binary_crossentropy: 0.5213 - val_loss: 0.6505 - val_binary_crossentropy: 0.6505\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 17s 772ms/step - loss: 0.5169 - binary_crossentropy: 0.5169 - val_loss: 0.6397 - val_binary_crossentropy: 0.6397\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 18s 815ms/step - loss: 0.5114 - binary_crossentropy: 0.5114 - val_loss: 0.6353 - val_binary_crossentropy: 0.6353\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 17s 792ms/step - loss: 0.5092 - binary_crossentropy: 0.5092 - val_loss: 0.6276 - val_binary_crossentropy: 0.6276\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 17s 759ms/step - loss: 0.5030 - binary_crossentropy: 0.5030 - val_loss: 0.6174 - val_binary_crossentropy: 0.6174\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 17s 761ms/step - loss: 0.4993 - binary_crossentropy: 0.4993 - val_loss: 0.6041 - val_binary_crossentropy: 0.6041\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 17s 765ms/step - loss: 0.4952 - binary_crossentropy: 0.4952 - val_loss: 0.5950 - val_binary_crossentropy: 0.5950\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 17s 752ms/step - loss: 0.4920 - binary_crossentropy: 0.4920 - val_loss: 0.5805 - val_binary_crossentropy: 0.5805\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 17s 763ms/step - loss: 0.4906 - binary_crossentropy: 0.4906 - val_loss: 0.5733 - val_binary_crossentropy: 0.5733\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 17s 764ms/step - loss: 0.4879 - binary_crossentropy: 0.4879 - val_loss: 0.5645 - val_binary_crossentropy: 0.5645\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 17s 759ms/step - loss: 0.4868 - binary_crossentropy: 0.4868 - val_loss: 0.5496 - val_binary_crossentropy: 0.5496\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 17s 753ms/step - loss: 0.4818 - binary_crossentropy: 0.4818 - val_loss: 0.5375 - val_binary_crossentropy: 0.5375\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 17s 758ms/step - loss: 0.4822 - binary_crossentropy: 0.4822 - val_loss: 0.5321 - val_binary_crossentropy: 0.5321\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 17s 760ms/step - loss: 0.4750 - binary_crossentropy: 0.4750 - val_loss: 0.5283 - val_binary_crossentropy: 0.5283\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 17s 772ms/step - loss: 0.4729 - binary_crossentropy: 0.4729 - val_loss: 0.5319 - val_binary_crossentropy: 0.5319\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 17s 775ms/step - loss: 0.4729 - binary_crossentropy: 0.4729 - val_loss: 0.5219 - val_binary_crossentropy: 0.5219\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 17s 761ms/step - loss: 0.4687 - binary_crossentropy: 0.4687 - val_loss: 0.5168 - val_binary_crossentropy: 0.5168\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 17s 755ms/step - loss: 0.4717 - binary_crossentropy: 0.4717 - val_loss: 0.5206 - val_binary_crossentropy: 0.5206\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 17s 769ms/step - loss: 0.4644 - binary_crossentropy: 0.4644 - val_loss: 0.5208 - val_binary_crossentropy: 0.5208\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 17s 787ms/step - loss: 0.4659 - binary_crossentropy: 0.4659 - val_loss: 0.5252 - val_binary_crossentropy: 0.5252\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 17s 760ms/step - loss: 0.4618 - binary_crossentropy: 0.4618 - val_loss: 0.5248 - val_binary_crossentropy: 0.5248\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 16s 740ms/step - loss: 0.4549 - binary_crossentropy: 0.4549 - val_loss: 0.5279 - val_binary_crossentropy: 0.5279\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 28s 1s/step - loss: 0.6697 - binary_crossentropy: 0.6697 - val_loss: 0.6642 - val_binary_crossentropy: 0.6642\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 16s 745ms/step - loss: 0.5492 - binary_crossentropy: 0.5492 - val_loss: 0.6552 - val_binary_crossentropy: 0.6552\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 16s 750ms/step - loss: 0.5320 - binary_crossentropy: 0.5320 - val_loss: 0.6478 - val_binary_crossentropy: 0.6478\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 16s 746ms/step - loss: 0.5256 - binary_crossentropy: 0.5256 - val_loss: 0.6396 - val_binary_crossentropy: 0.6396\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 17s 770ms/step - loss: 0.5189 - binary_crossentropy: 0.5189 - val_loss: 0.6310 - val_binary_crossentropy: 0.6310\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 17s 755ms/step - loss: 0.5160 - binary_crossentropy: 0.5160 - val_loss: 0.6214 - val_binary_crossentropy: 0.6214\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 17s 755ms/step - loss: 0.5115 - binary_crossentropy: 0.5115 - val_loss: 0.6144 - val_binary_crossentropy: 0.6144\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 17s 754ms/step - loss: 0.5088 - binary_crossentropy: 0.5088 - val_loss: 0.6021 - val_binary_crossentropy: 0.6021\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 17s 750ms/step - loss: 0.5005 - binary_crossentropy: 0.5005 - val_loss: 0.5874 - val_binary_crossentropy: 0.5874\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 17s 763ms/step - loss: 0.4993 - binary_crossentropy: 0.4993 - val_loss: 0.5825 - val_binary_crossentropy: 0.5825\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 17s 756ms/step - loss: 0.4949 - binary_crossentropy: 0.4949 - val_loss: 0.5598 - val_binary_crossentropy: 0.5598\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 17s 751ms/step - loss: 0.4906 - binary_crossentropy: 0.4906 - val_loss: 0.5551 - val_binary_crossentropy: 0.5551\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 17s 767ms/step - loss: 0.4877 - binary_crossentropy: 0.4877 - val_loss: 0.5576 - val_binary_crossentropy: 0.5576\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 17s 761ms/step - loss: 0.4866 - binary_crossentropy: 0.4866 - val_loss: 0.5430 - val_binary_crossentropy: 0.5430\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 16s 739ms/step - loss: 0.4837 - binary_crossentropy: 0.4837 - val_loss: 0.5344 - val_binary_crossentropy: 0.5344\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 17s 752ms/step - loss: 0.4809 - binary_crossentropy: 0.4809 - val_loss: 0.5311 - val_binary_crossentropy: 0.5311\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 17s 756ms/step - loss: 0.4763 - binary_crossentropy: 0.4763 - val_loss: 0.5184 - val_binary_crossentropy: 0.5184\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 17s 769ms/step - loss: 0.4712 - binary_crossentropy: 0.4712 - val_loss: 0.5236 - val_binary_crossentropy: 0.5236\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 17s 757ms/step - loss: 0.4702 - binary_crossentropy: 0.4702 - val_loss: 0.5249 - val_binary_crossentropy: 0.5249\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 18s 808ms/step - loss: 0.4675 - binary_crossentropy: 0.4675 - val_loss: 0.5213 - val_binary_crossentropy: 0.5213\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 17s 749ms/step - loss: 0.4648 - binary_crossentropy: 0.4648 - val_loss: 0.5243 - val_binary_crossentropy: 0.5243\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 17s 754ms/step - loss: 0.4649 - binary_crossentropy: 0.4649 - val_loss: 0.5234 - val_binary_crossentropy: 0.5234\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 30s 1s/step - loss: 0.6181 - binary_crossentropy: 0.6181 - val_loss: 0.6645 - val_binary_crossentropy: 0.6645\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 16s 748ms/step - loss: 0.5325 - binary_crossentropy: 0.5325 - val_loss: 0.6553 - val_binary_crossentropy: 0.6553\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 16s 738ms/step - loss: 0.5194 - binary_crossentropy: 0.5194 - val_loss: 0.6498 - val_binary_crossentropy: 0.6498\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 16s 744ms/step - loss: 0.5146 - binary_crossentropy: 0.5146 - val_loss: 0.6421 - val_binary_crossentropy: 0.6421\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 17s 758ms/step - loss: 0.5091 - binary_crossentropy: 0.5091 - val_loss: 0.6298 - val_binary_crossentropy: 0.6298\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 16s 736ms/step - loss: 0.5051 - binary_crossentropy: 0.5051 - val_loss: 0.6235 - val_binary_crossentropy: 0.6235\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 16s 748ms/step - loss: 0.5001 - binary_crossentropy: 0.5001 - val_loss: 0.6097 - val_binary_crossentropy: 0.6097\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 17s 767ms/step - loss: 0.4963 - binary_crossentropy: 0.4963 - val_loss: 0.5989 - val_binary_crossentropy: 0.5989\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 17s 760ms/step - loss: 0.4924 - binary_crossentropy: 0.4924 - val_loss: 0.5887 - val_binary_crossentropy: 0.5887\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 17s 758ms/step - loss: 0.4935 - binary_crossentropy: 0.4935 - val_loss: 0.5785 - val_binary_crossentropy: 0.5785\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 17s 769ms/step - loss: 0.4859 - binary_crossentropy: 0.4859 - val_loss: 0.5701 - val_binary_crossentropy: 0.5701\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 17s 763ms/step - loss: 0.4861 - binary_crossentropy: 0.4861 - val_loss: 0.5504 - val_binary_crossentropy: 0.5504\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 17s 754ms/step - loss: 0.4817 - binary_crossentropy: 0.4817 - val_loss: 0.5493 - val_binary_crossentropy: 0.5493\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 16s 731ms/step - loss: 0.4761 - binary_crossentropy: 0.4761 - val_loss: 0.5378 - val_binary_crossentropy: 0.5378\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 16s 745ms/step - loss: 0.4729 - binary_crossentropy: 0.4729 - val_loss: 0.5272 - val_binary_crossentropy: 0.5272\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 16s 741ms/step - loss: 0.4721 - binary_crossentropy: 0.4721 - val_loss: 0.5202 - val_binary_crossentropy: 0.5202\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 17s 756ms/step - loss: 0.4693 - binary_crossentropy: 0.4693 - val_loss: 0.5259 - val_binary_crossentropy: 0.5259\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 17s 759ms/step - loss: 0.4656 - binary_crossentropy: 0.4656 - val_loss: 0.5329 - val_binary_crossentropy: 0.5329\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 17s 757ms/step - loss: 0.4662 - binary_crossentropy: 0.4662 - val_loss: 0.5283 - val_binary_crossentropy: 0.5283\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 17s 763ms/step - loss: 0.4647 - binary_crossentropy: 0.4647 - val_loss: 0.5220 - val_binary_crossentropy: 0.5220\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 16s 727ms/step - loss: 0.4552 - binary_crossentropy: 0.4552 - val_loss: 0.5228 - val_binary_crossentropy: 0.5228\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "y_preds = []\n",
    "models = []\n",
    "oof_train = np.zeros((len(X_train),))\n",
    "\n",
    "for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_tr = X_train.iloc[train_index, :]\n",
    "    X_val = X_train.iloc[valid_index, :]\n",
    "    y_tr = y_train.iloc[train_index]\n",
    "    y_val = y_train.iloc[valid_index]\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Reshape((256, 16)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Conv1D(filters=16, kernel_size=5, strides=1, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[keras.metrics.BinaryCrossentropy()]\n",
    "    )\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        patience=10,\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=10000,\n",
    "        epochs=100,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    oof_train[valid_index] = model.predict(X_val).reshape(1, -1)[0]\n",
    "    y_pred = model.predict(X_test).reshape(1, -1)[0]\n",
    "\n",
    "    y_preds.append(y_pred)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for test set is 0.6371\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for test set is \" + \n",
    "      str(round(accuracy_score(y_test, np.where((sum(y_preds) / len(y_preds)) > .2776,\n",
    "                                                                        1, 0)),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for test set is 0.5376\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score for test set is \" + \n",
    "      str(round(f1_score(y_test, np.where((sum(y_preds) / len(y_preds)) > .2776,\n",
    "                                                                        1, 0)),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24122, 16757],\n",
       "       [ 3784, 11939]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, np.where((sum(y_preds) / len(y_preds)) > .2776, 1, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
